{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "461f05bf-8fb0-4ebb-acbc-dbc6be301434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\iscu02\\appdata\\local\\miniconda3\\envs\\ics5110\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy>=1.23.2 in c:\\users\\iscu02\\appdata\\local\\miniconda3\\envs\\ics5110\\lib\\site-packages (from pandas) (2.3.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\iscu02\\appdata\\local\\miniconda3\\envs\\ics5110\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\iscu02\\appdata\\local\\miniconda3\\envs\\ics5110\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\iscu02\\appdata\\local\\miniconda3\\envs\\ics5110\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\iscu02\\appdata\\local\\miniconda3\\envs\\ics5110\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01427bba-4f5c-45ea-8ae9-f2557214c4c0",
   "metadata": {},
   "source": [
    "# Data Exploration & Feature Engineering\n",
    "\n",
    "This notebook processes police press releases and news articles to extract accident datetime information and prepare the data for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1bfa618a-3e5d-4c5d-b05a-2ef2fce3bb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import requests\n",
    "from typing import Dict, List\n",
    "import warnings\n",
    "import re\n",
    "import os\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration\n",
    "DATA_PATH = \"C:\\\\Python\\\\ics5110-assignment\\\\data\\\\\"\n",
    "OUTPUT_PATH = \"C:\\\\Python\\\\ics5110-assignment\\\\data\\\\processed\\\\\"\n",
    "os.makedirs(OUTPUT_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d44ab8-c251-4014-8177-7c9332b6c129",
   "metadata": {},
   "source": [
    "# 1. Load and Explore Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "67006ec0-f817-4982-98ca-bc3bd2724522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Articles dataset shape: (321, 14)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 321 entries, 0 to 320\n",
      "Data columns (total 14 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   article_id         321 non-null    int64 \n",
      " 1   url                321 non-null    object\n",
      " 2   source_name        321 non-null    object\n",
      " 3   source_url         321 non-null    object\n",
      " 4   title              321 non-null    object\n",
      " 5   subtitle           313 non-null    object\n",
      " 6   author_name        321 non-null    object\n",
      " 7   publish_date       321 non-null    object\n",
      " 8   content            321 non-null    object\n",
      " 9   top_image_url      318 non-null    object\n",
      " 10  top_image_caption  312 non-null    object\n",
      " 11  created_at         321 non-null    object\n",
      " 12  tags               321 non-null    object\n",
      " 13  categories         321 non-null    object\n",
      "dtypes: int64(1), object(13)\n",
      "memory usage: 35.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# Load articles dataset\n",
    "articles_df = pd.read_csv(f\"{DATA_PATH}local_news_articles.csv\")\n",
    "print(f\"Articles dataset shape: {articles_df.shape}\")\n",
    "articles_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7dbf8b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Police releases dataset shape: (111, 5)\n",
      "Primary key range: 1 to 111\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 111 entries, 0 to 110\n",
      "Data columns (total 5 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   release_id      111 non-null    int64 \n",
      " 1   title           111 non-null    object\n",
      " 2   date_published  111 non-null    object\n",
      " 3   date_modified   111 non-null    object\n",
      " 4   content         111 non-null    object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 4.5+ KB\n",
      "\n",
      "================================================================================\n",
      "Sample police press release:\n",
      "Release ID: 1\n",
      "Published: 2025-10-09\n",
      "Content: Today, at around 0930hrs, the Police were informed of a traffic accident on Triq il-Belt Valletta, Å»urrieq.The Police immediately went to the scene and from a preliminary investigation it resulted tha...\n"
     ]
    }
   ],
   "source": [
    "# Load police releases dataset with primary key\n",
    "police_releases_df = pd.read_csv(f\"{DATA_PATH}police_press_releases.csv\")\n",
    "police_releases_df.insert(0, 'release_id', range(1, len(police_releases_df) + 1))\n",
    "\n",
    "print(f\"Police releases dataset shape: {police_releases_df.shape}\")\n",
    "print(f\"Primary key range: {police_releases_df['release_id'].min()} to {police_releases_df['release_id'].max()}\")\n",
    "police_releases_df.info()\n",
    "\n",
    "# Display sample\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Sample police press release:\")\n",
    "print(f\"Release ID: {police_releases_df['release_id'].iloc[0]}\")\n",
    "print(f\"Published: {police_releases_df['date_published'].iloc[0]}\")\n",
    "print(f\"Content: {police_releases_df['content'].iloc[0][:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff882f5",
   "metadata": {},
   "source": [
    "# 2. Accident DateTime Extraction Function\n",
    "\n",
    "Extract accident date and time from police press release content with high accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f4a17949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Extraction function loaded\n"
     ]
    }
   ],
   "source": [
    "def extract_accident_datetime_improved(content: str, published_date: str) -> dict:\n",
    "    \"\"\"\n",
    "    Extract accident date and time from police press release content.\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with accident_datetime, accident_date, accident_time, time_confidence\n",
    "    \"\"\"\n",
    "    result = {\n",
    "        'accident_datetime': None,\n",
    "        'accident_date': None,\n",
    "        'accident_time': None,\n",
    "        'time_confidence': 'low'\n",
    "    }\n",
    "    \n",
    "    if pd.isna(content) or pd.isna(published_date):\n",
    "        return result\n",
    "    \n",
    "    content_lower = content.lower()\n",
    "    published_dt = pd.to_datetime(published_date)\n",
    "    extracted_time = None\n",
    "    \n",
    "    # HIGH confidence: Exact time with \"hrs\"\n",
    "    hrs_patterns = [\n",
    "        (r'at around (\\d{4})\\s*hrs', 1), (r'at (\\d{4})\\s*hrs', 1),\n",
    "        (r'around (\\d{4})\\s*hrs', 1), (r'\\((\\d{4})\\s*hrs\\)', 1),\n",
    "        (r'\\w+\\s*\\((\\d{4})\\s*hrs\\)', 1),\n",
    "        (r'at around (\\d{1,2}):(\\d{2})\\s*hrs', 2), (r'at (\\d{1,2}):(\\d{2})\\s*hrs', 2),\n",
    "        (r'around (\\d{1,2}):(\\d{2})\\s*hrs', 2),\n",
    "        (r'at around (\\d{1,2})\\.(\\d{2})\\s*hrs', 2), (r'at (\\d{1,2})\\.(\\d{2})\\s*hrs', 2),\n",
    "    ]\n",
    "    \n",
    "    for pattern, num_groups in hrs_patterns:\n",
    "        match = re.search(pattern, content_lower)\n",
    "        if match:\n",
    "            if num_groups == 1:\n",
    "                time_str = match.group(1)\n",
    "                if len(time_str) == 4:\n",
    "                    hour, minute = int(time_str[:2]), int(time_str[2:])\n",
    "                    if 0 <= hour <= 23 and 0 <= minute <= 59:\n",
    "                        extracted_time = f\"{hour:02d}:{minute:02d}\"\n",
    "                        result['time_confidence'] = 'high'\n",
    "                        break\n",
    "            else:\n",
    "                hour, minute = int(match.group(1)), int(match.group(2))\n",
    "                if 0 <= hour <= 23 and 0 <= minute <= 59:\n",
    "                    extracted_time = f\"{hour:02d}:{minute:02d}\"\n",
    "                    result['time_confidence'] = 'high'\n",
    "                    break\n",
    "    \n",
    "    # HIGH confidence: Standard time formats without \"hrs\"\n",
    "    if not extracted_time:\n",
    "        time_patterns = [\n",
    "            (r'at around (\\d{1,2}):(\\d{2})', 2), (r'at (\\d{1,2}):(\\d{2})', 2),\n",
    "            (r'around (\\d{1,2}):(\\d{2})', 2),\n",
    "            (r'at around (\\d{1,2})\\.(\\d{2})', 2), (r'at (\\d{1,2})\\.(\\d{2})', 2),\n",
    "        ]\n",
    "        for pattern, _ in time_patterns:\n",
    "            match = re.search(pattern, content_lower)\n",
    "            if match:\n",
    "                hour, minute = int(match.group(1)), int(match.group(2))\n",
    "                if 0 <= hour <= 23 and 0 <= minute <= 59:\n",
    "                    extracted_time = f\"{hour:02d}:{minute:02d}\"\n",
    "                    result['time_confidence'] = 'high'\n",
    "                    break\n",
    "    \n",
    "    # MEDIUM-HIGH confidence: Specific time markers\n",
    "    if not extracted_time:\n",
    "        time_markers = [\n",
    "            (r'\\bmidnight\\b', '00:00', 'high'), (r'\\bnoon\\b|\\bmidday\\b', '12:00', 'high'),\n",
    "            (r'\\bdawn\\b|\\bsunrise\\b', '06:00', 'medium'), (r'\\bdusk\\b|\\bsunset\\b', '19:00', 'medium'),\n",
    "        ]\n",
    "        for pattern, time, conf in time_markers:\n",
    "            if re.search(pattern, content_lower):\n",
    "                extracted_time, result['time_confidence'] = time, conf\n",
    "                break\n",
    "    \n",
    "    # MEDIUM confidence: Time ranges (calculate midpoint)\n",
    "    if not extracted_time:\n",
    "        match = re.search(r'between (\\d{1,2})[:\\.]?(\\d{2})?\\s*(?:and|&|-)\\s*(\\d{1,2})[:\\.]?(\\d{2})?', content_lower)\n",
    "        if match:\n",
    "            hour1 = int(match.group(1))\n",
    "            min1 = int(match.group(2)) if match.group(2) else 0\n",
    "            hour2 = int(match.group(3))\n",
    "            min2 = int(match.group(4)) if match.group(4) else 0\n",
    "            if 0 <= hour1 <= 23 and 0 <= hour2 <= 23:\n",
    "                mid_minutes = ((hour1 * 60 + min1) + (hour2 * 60 + min2)) // 2\n",
    "                extracted_time = f\"{mid_minutes // 60:02d}:{mid_minutes % 60:02d}\"\n",
    "                result['time_confidence'] = 'medium'\n",
    "    \n",
    "    # MEDIUM confidence: General time periods\n",
    "    if not extracted_time:\n",
    "        time_periods = [\n",
    "            (r'\\bearly hours\\b', '03:00'), (r'\\blate hours\\b|\\blate at night\\b', '23:00'),\n",
    "            (r'\\bearly morning\\b', '06:00'), (r'\\bmorning\\b', '09:00'),\n",
    "            (r'\\bafternoon\\b', '15:00'), (r'\\bevening\\b', '19:00'), (r'\\bnight\\b', '22:00'),\n",
    "        ]\n",
    "        for pattern, time in time_periods:\n",
    "            if re.search(pattern, content_lower):\n",
    "                extracted_time, result['time_confidence'] = time, 'medium'\n",
    "                break\n",
    "    \n",
    "    # Date extraction\n",
    "    accident_date = None\n",
    "    explicit_patterns = [\n",
    "        (r'on (\\d{1,2}(?:st|nd|rd|th)?\\s+(?:january|february|march|april|may|june|july|august|september|october|november|december))', '%d %B'),\n",
    "        (r'on ((?:january|february|march|april|may|june|july|august|september|october|november|december)\\s+\\d{1,2}(?:st|nd|rd|th)?)', '%B %d'),\n",
    "    ]\n",
    "    \n",
    "    for pattern, date_format in explicit_patterns:\n",
    "        match = re.search(pattern, content_lower)\n",
    "        if match:\n",
    "            try:\n",
    "                date_str = re.sub(r'(st|nd|rd|th)', '', match.group(1))\n",
    "                accident_date = pd.to_datetime(date_str, format=date_format).replace(year=published_dt.year)\n",
    "                if accident_date > published_dt + timedelta(days=30):\n",
    "                    accident_date = accident_date.replace(year=published_dt.year - 1)\n",
    "                break\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    if accident_date is None:\n",
    "        if re.search(r'^\\s*today[,\\s]|^today at', content_lower):\n",
    "            accident_date = published_dt\n",
    "        elif re.search(r'^\\s*yesterday[,\\s]|^yesterday at', content_lower):\n",
    "            accident_date = published_dt - timedelta(days=1)\n",
    "        elif re.search(r'\\bthis morning\\b', content_lower):\n",
    "            accident_date = published_dt\n",
    "        elif re.search(r'\\blast night\\b', content_lower):\n",
    "            accident_date = published_dt - timedelta(days=1)\n",
    "        elif re.search(r'\\blast evening\\b', content_lower):\n",
    "            accident_date = published_dt - timedelta(days=1)\n",
    "        elif match := re.search(r'\\blast (monday|tuesday|wednesday|thursday|friday|saturday|sunday)', content_lower):\n",
    "            days = ['monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday']\n",
    "            days_back = (published_dt.weekday() - days.index(match.group(1))) % 7 or 7\n",
    "            accident_date = published_dt - timedelta(days=days_back)\n",
    "        else:\n",
    "            accident_date = published_dt\n",
    "    \n",
    "    # Combine date and time\n",
    "    if accident_date is not None:\n",
    "        result['accident_date'] = accident_date.date()\n",
    "        if extracted_time:\n",
    "            try:\n",
    "                hour, minute = map(int, extracted_time.split(':'))\n",
    "                result['accident_datetime'] = accident_date.replace(hour=hour, minute=minute, second=0)\n",
    "                result['accident_time'] = extracted_time\n",
    "            except:\n",
    "                result['accident_datetime'] = accident_date\n",
    "        else:\n",
    "            result['accident_datetime'] = accident_date\n",
    "    \n",
    "    return result\n",
    "\n",
    "print(\"âœ“ Extraction function loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9533bc2c",
   "metadata": {},
   "source": [
    "# 3. Extract Accident DateTime for All Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "292f45f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting accident datetime...\n",
      "\n",
      "âœ“ Extraction complete!\n",
      "Total: 111 | High: 106 (95.5%) | Medium: 1 (0.9%) | Low: 4 (3.6%)\n"
     ]
    }
   ],
   "source": [
    "print(\"Extracting accident datetime...\")\n",
    "\n",
    "# Apply extraction\n",
    "extraction_results = police_releases_df.apply(\n",
    "    lambda row: extract_accident_datetime_improved(row['content'], row['date_published']), axis=1\n",
    ")\n",
    "\n",
    "# Add columns\n",
    "extraction_df = pd.DataFrame(extraction_results.tolist())\n",
    "for col in ['accident_datetime', 'accident_date', 'accident_time', 'time_confidence']:\n",
    "    police_releases_df[col] = extraction_df[col]\n",
    "\n",
    "# Add derived features\n",
    "police_releases_df['accident_hour'] = pd.to_datetime(police_releases_df['accident_datetime']).dt.hour\n",
    "police_releases_df['accident_day_of_week'] = pd.to_datetime(police_releases_df['accident_datetime']).dt.dayofweek\n",
    "police_releases_df['accident_is_weekend'] = police_releases_df['accident_day_of_week'].isin([5, 6]).astype(int)\n",
    "police_releases_df['publication_delay_hours'] = (\n",
    "    pd.to_datetime(police_releases_df['date_published']) - \n",
    "    pd.to_datetime(police_releases_df['accident_datetime'])\n",
    ").dt.total_seconds() / 3600\n",
    "\n",
    "def categorize_time_of_day(hour):\n",
    "    if pd.isna(hour): return None\n",
    "    if 0 <= hour < 6: return 'Night (00:00-06:00)'\n",
    "    if 6 <= hour < 12: return 'Morning (06:00-12:00)'\n",
    "    if 12 <= hour < 18: return 'Afternoon (12:00-18:00)'\n",
    "    return 'Evening (18:00-00:00)'\n",
    "\n",
    "police_releases_df['time_of_day_category'] = police_releases_df['accident_hour'].apply(categorize_time_of_day)\n",
    "\n",
    "# Summary\n",
    "total = len(police_releases_df)\n",
    "high = (police_releases_df['time_confidence'] == 'high').sum()\n",
    "medium = (police_releases_df['time_confidence'] == 'medium').sum()\n",
    "low = (police_releases_df['time_confidence'] == 'low').sum()\n",
    "\n",
    "print(f\"\\nâœ“ Extraction complete!\")\n",
    "print(f\"Total: {total} | High: {high} ({high/total*100:.1f}%) | Medium: {medium} ({medium/total*100:.1f}%) | Low: {low} ({low/total*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84db588a",
   "metadata": {},
   "source": [
    "# 4. Manual Corrections for Low Confidence Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ee0b06fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low confidence records: 4\n",
      "\n",
      "ID: 16 | Published: 2025-04-17 | Current: None\n",
      "Content: An 80-year-old man, a resident of Santa LuÄ‹ija, was taken to Mater Dei Hospital for some injuries he sustained in a traffic accident in Luqa Road, Luq...\n",
      "--------------------------------------------------------------------------------\n",
      "ID: 25 | Published: 2024-12-27 | Current: None\n",
      "Content: Today, at about 0745hrs, the Police were informed of a traffic accident in Triq DiÄ‹embru Tlettax, Marsa.The Police went immediately on site and prelim...\n",
      "--------------------------------------------------------------------------------\n",
      "ID: 76 | Published: 2025-04-14 | Current: None\n",
      "Content: Yesterday, at about 1745hrs, the Police were informed of a traffic accident in BirÅ¼ebbuÄ¡a Road, BirÅ¼ebbuÄ¡a.Preliminary investigations found that a col...\n",
      "--------------------------------------------------------------------------------\n",
      "ID: 77 | Published: 2025-07-24 | Current: None\n",
      "Content: A 65-year-old man, a resident of MellieÄ§a, was taken to Mater Dei Hospital at about 1015 hrs after he was injured in an accident in Salina Road, Naxxa...\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Display low confidence records\n",
    "low_conf = police_releases_df[police_releases_df['time_confidence'] == 'low']\n",
    "print(f\"Low confidence records: {len(low_conf)}\\n\")\n",
    "\n",
    "if len(low_conf) > 0:\n",
    "    for idx, row in low_conf.head(10).iterrows():\n",
    "        print(f\"ID: {row['release_id']} | Published: {row['date_published']} | Current: {row['accident_time']}\")\n",
    "        print(f\"Content: {row['content'][:150]}...\")\n",
    "        print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d64beae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Release ID 25: 07:45\n",
      "âœ“ Release ID 76: 17:45\n",
      "âœ“ Release ID 77: 10:15\n",
      "\n",
      "âœ“ 3 manual corrections applied\n"
     ]
    }
   ],
   "source": [
    "# Manual corrections dictionary - add your corrections here\n",
    "manual_corrections = {\n",
    "    25: {'time': '07:45'},\n",
    "    76: {'time': '17:45'},\n",
    "    77: {'time': '10:15'}\n",
    "    # Add more: release_id: {'time': 'HH:MM', 'date': 'YYYY-MM-DD'}\n",
    "}\n",
    "\n",
    "def apply_manual_corrections(df, corrections):\n",
    "    \"\"\"Apply manual time/date corrections to the dataframe.\"\"\"\n",
    "    df = df.copy()\n",
    "    corrections_applied = 0\n",
    "    \n",
    "    for release_id, correction_data in corrections.items():\n",
    "        mask = df['release_id'] == release_id\n",
    "        if not mask.any():\n",
    "            print(f\"âš  Release ID {release_id} not found\")\n",
    "            continue\n",
    "        \n",
    "        idx = df[mask].index[0]\n",
    "        \n",
    "        # Determine date\n",
    "        if 'date' in correction_data:\n",
    "            new_date = pd.to_datetime(correction_data['date'])\n",
    "        else:\n",
    "            new_date = pd.to_datetime(df.loc[idx, 'accident_date'] if pd.notna(df.loc[idx, 'accident_date']) \n",
    "                                     else df.loc[idx, 'date_published'])\n",
    "        \n",
    "        # Apply time\n",
    "        if 'time' in correction_data:\n",
    "            try:\n",
    "                hour, minute = map(int, correction_data['time'].split(':'))\n",
    "                if 0 <= hour <= 23 and 0 <= minute <= 59:\n",
    "                    df.loc[idx, 'accident_time'] = f\"{hour:02d}:{minute:02d}\"\n",
    "                    df.loc[idx, 'accident_datetime'] = new_date.replace(hour=hour, minute=minute, second=0)\n",
    "                    df.loc[idx, 'accident_date'] = new_date.date()\n",
    "                    df.loc[idx, 'accident_hour'] = hour\n",
    "                    df.loc[idx, 'time_of_day_category'] = categorize_time_of_day(hour)\n",
    "                    df.loc[idx, 'time_confidence'] = 'manual'\n",
    "                    df.loc[idx, 'publication_delay_hours'] = (\n",
    "                        pd.to_datetime(df.loc[idx, 'date_published']) - df.loc[idx, 'accident_datetime']\n",
    "                    ).total_seconds() / 3600\n",
    "                    corrections_applied += 1\n",
    "                    print(f\"âœ“ Release ID {release_id}: {correction_data['time']}\")\n",
    "                else:\n",
    "                    print(f\"âœ— Invalid time for {release_id}: {correction_data['time']}\")\n",
    "            except Exception as e:\n",
    "                print(f\"âœ— Error for {release_id}: {e}\")\n",
    "    \n",
    "    return df, corrections_applied\n",
    "\n",
    "if manual_corrections:\n",
    "    police_releases_df, num_applied = apply_manual_corrections(police_releases_df, manual_corrections)\n",
    "    print(f\"\\nâœ“ {num_applied} manual corrections applied\")\n",
    "else:\n",
    "    print(\"No manual corrections defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e725c6",
   "metadata": {},
   "source": [
    "# 5. Final Statistics & Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b9dac719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "FINAL DATASET STATISTICS\n",
      "================================================================================\n",
      "\n",
      "ðŸ“Š Confidence Distribution:\n",
      "   High:    106 ( 95.5%)\n",
      "   Medium:    1 (  0.9%)\n",
      "   Manual:    3 (  2.7%)\n",
      "   Low:       1 (  0.9%)\n",
      "\n",
      "   Coverage:  110 / 111 (99.1%)\n",
      "\n",
      "â° Time Distribution:\n",
      "time_of_day_category\n",
      "Afternoon (12:00-18:00)    29\n",
      "Evening (18:00-00:00)      27\n",
      "Morning (06:00-12:00)      46\n",
      "Night (00:00-06:00)         9\n",
      "Name: count, dtype: int64\n",
      "\n",
      "ðŸ“… Day Distribution:\n",
      "   Mon: 11\n",
      "   Tue: 15\n",
      "   Wed: 17\n",
      "   Thu: 19\n",
      "   Fri: 12\n",
      "   Sat: 14\n",
      "   Sun: 23\n",
      "\n",
      "ðŸ“° Publication Timing:\n",
      "   Average delay: -6.94 hours\n",
      "   Median delay:  -9.00 hours\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Sample records:\n",
      "   release_id   accident_datetime accident_time time_confidence\n",
      "0           1 2025-10-09 09:30:00         09:30            high\n",
      "1           2 2025-06-19 18:30:00         18:30            high\n",
      "2           3 2025-05-12 08:00:00         08:00            high\n",
      "3           4 2025-07-29 18:00:00         18:00            high\n",
      "4           5 2025-04-06 20:45:00         20:45            high\n",
      "5           6 2025-04-15 08:50:00         08:50            high\n",
      "6           7 2025-07-23 10:30:00         10:30            high\n",
      "7           8 2025-08-03 08:15:00         08:15            high\n",
      "8           9 2025-06-14 15:45:00         15:45            high\n",
      "9          10 2024-12-28 09:15:00         09:15            high\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"FINAL DATASET STATISTICS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "total = len(police_releases_df)\n",
    "high = (police_releases_df['time_confidence'] == 'high').sum()\n",
    "medium = (police_releases_df['time_confidence'] == 'medium').sum()\n",
    "manual = (police_releases_df['time_confidence'] == 'manual').sum()\n",
    "low = (police_releases_df['time_confidence'] == 'low').sum()\n",
    "\n",
    "print(f\"\\nðŸ“Š Confidence Distribution:\")\n",
    "print(f\"   High:   {high:4d} ({high/total*100:5.1f}%)\")\n",
    "print(f\"   Medium: {medium:4d} ({medium/total*100:5.1f}%)\")\n",
    "print(f\"   Manual: {manual:4d} ({manual/total*100:5.1f}%)\")\n",
    "print(f\"   Low:    {low:4d} ({low/total*100:5.1f}%)\")\n",
    "print(f\"\\n   Coverage: {high+medium+manual:4d} / {total} ({(high+medium+manual)/total*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nâ° Time Distribution:\")\n",
    "print(police_releases_df['time_of_day_category'].value_counts().sort_index())\n",
    "\n",
    "print(f\"\\nðŸ“… Day Distribution:\")\n",
    "day_names = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
    "for day_num, count in police_releases_df['accident_day_of_week'].value_counts().sort_index().items():\n",
    "    if not pd.isna(day_num):\n",
    "        print(f\"   {day_names[int(day_num)]}: {count}\")\n",
    "\n",
    "print(f\"\\nðŸ“° Publication Timing:\")\n",
    "print(f\"   Average delay: {police_releases_df['publication_delay_hours'].mean():.2f} hours\")\n",
    "print(f\"   Median delay:  {police_releases_df['publication_delay_hours'].median():.2f} hours\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "\n",
    "# Sample output\n",
    "print(\"\\nSample records:\")\n",
    "print(police_releases_df[['release_id', 'accident_datetime', 'accident_time', 'time_confidence']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c024770",
   "metadata": {},
   "source": [
    "# 6. Save Final Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4a9925ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Datasets saved successfully!\n",
      "\n",
      "Files created:\n",
      "1. C:\\Python\\ics5110-assignment\\data\\processed\\police_releases_with_acc_datetime.csv - Full dataset\n",
      "2. C:\\Python\\ics5110-assignment\\data\\processed\\police_releases_summary.csv - Summary with key features\n",
      "3. C:\\Python\\ics5110-assignment\\data\\processed\\low_confidence_review.csv - Low confidence records for manual review\n",
      "\n",
      "ðŸ“Š Dataset ready for analysis and modeling!\n"
     ]
    }
   ],
   "source": [
    "# Save full dataset\n",
    "police_releases_df.to_csv(f\"{OUTPUT_PATH}police_releases_with_acc_datetime.csv\", index=False)\n",
    "\n",
    "# Save summary dataset\n",
    "summary_columns = [\n",
    "    'release_id', 'date_published', 'accident_datetime', 'accident_date', \n",
    "    'accident_time', 'accident_hour', 'time_of_day_category',\n",
    "    'accident_day_of_week', 'accident_is_weekend', 'time_confidence',\n",
    "    'publication_delay_hours'\n",
    "]\n",
    "police_releases_df[summary_columns].to_csv(f\"{OUTPUT_PATH}police_releases_summary.csv\", index=False)\n",
    "\n",
    "# Export low confidence for external review (CSV)\n",
    "low_conf = police_releases_df[police_releases_df['time_confidence'] == 'low'][\n",
    "    ['release_id', 'date_published', 'accident_time', 'accident_date', 'content']\n",
    "].copy()\n",
    "low_conf['corrected_time'] = ''\n",
    "low_conf['corrected_date'] = ''\n",
    "low_conf.to_csv(f\"{OUTPUT_PATH}low_confidence_review.csv\", index=False)\n",
    "\n",
    "print(\"âœ“ Datasets saved successfully!\\n\")\n",
    "print(\"Files created:\")\n",
    "print(f\"1. {OUTPUT_PATH}police_releases_with_acc_datetime.csv - Full dataset\")\n",
    "print(f\"2. {OUTPUT_PATH}police_releases_summary.csv - Summary with key features\")\n",
    "print(f\"3. {OUTPUT_PATH}low_confidence_review.csv - Low confidence records for manual review\")\n",
    "print(f\"\\nðŸ“Š Dataset ready for analysis and modeling!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ics5110",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

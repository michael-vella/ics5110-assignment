{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5db74a6",
   "metadata": {},
   "source": [
    "# Road Accident Classification - Local News Articles\n",
    "\n",
    "This notebook analyzes the local_news_articles.csv dataset to identify and flag road accidents vs non-accidents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "df2a080d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (321, 14)\n",
      "\n",
      "Column names:\n",
      "['article_id', 'url', 'source_name', 'source_url', 'title', 'subtitle', 'author_name', 'publish_date', 'content', 'top_image_url', 'top_image_caption', 'created_at', 'tags', 'categories']\n",
      "\n",
      "First few rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>url</th>\n",
       "      <th>source_name</th>\n",
       "      <th>source_url</th>\n",
       "      <th>title</th>\n",
       "      <th>subtitle</th>\n",
       "      <th>author_name</th>\n",
       "      <th>publish_date</th>\n",
       "      <th>content</th>\n",
       "      <th>top_image_url</th>\n",
       "      <th>top_image_caption</th>\n",
       "      <th>created_at</th>\n",
       "      <th>tags</th>\n",
       "      <th>categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4208</td>\n",
       "      <td>https://timesofmalta.com/article/driver-stuck-...</td>\n",
       "      <td>Times of Malta</td>\n",
       "      <td>https://timesofmalta.com</td>\n",
       "      <td>Driver stuck in traffic says speeding LESA car...</td>\n",
       "      <td>‘I was shocked at that moment but more so frus...</td>\n",
       "      <td>Emma Borg</td>\n",
       "      <td>2024-12-07</td>\n",
       "      <td>A motorist claims his car mirror was shattered...</td>\n",
       "      <td>https://cdn-attachments.timesofmalta.com/706da...</td>\n",
       "      <td>The broken car mirror. Photo: Frank Xerri De Caro</td>\n",
       "      <td>2025-07-03 15:14:21.554132+00</td>\n",
       "      <td>{Accident,Lesa,National}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4167</td>\n",
       "      <td>https://timesofmalta.com/article/pn-slams-gove...</td>\n",
       "      <td>Times of Malta</td>\n",
       "      <td>https://timesofmalta.com</td>\n",
       "      <td>PN slams government for diverting EU bus funds...</td>\n",
       "      <td>'By encouraging the use of private cars, the g...</td>\n",
       "      <td>Times of Malta</td>\n",
       "      <td>2024-12-09</td>\n",
       "      <td>The PN on Monday slammed the government for di...</td>\n",
       "      <td>https://cdn-attachments.timesofmalta.com/d9afe...</td>\n",
       "      <td>PN spokespeople Ryan Callus, Mark Anthony Samm...</td>\n",
       "      <td>2025-07-03 15:14:10.643172+00</td>\n",
       "      <td>{\"Climate Change\",Environment,\"European Union\"...</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4093</td>\n",
       "      <td>https://timesofmalta.com/article/motorcyclist-...</td>\n",
       "      <td>Times of Malta</td>\n",
       "      <td>https://timesofmalta.com</td>\n",
       "      <td>Motorcyclist seriously hurt in St Paul's Bay b...</td>\n",
       "      <td>Residents complained several times about inade...</td>\n",
       "      <td>Times of Malta</td>\n",
       "      <td>2024-12-11</td>\n",
       "      <td>A motorcyclist was rushed to hospital in a cri...</td>\n",
       "      <td>https://cdn-attachments.timesofmalta.com/633f6...</td>\n",
       "      <td>Photo: Malta Police Force</td>\n",
       "      <td>2025-07-03 15:13:50.605708+00</td>\n",
       "      <td>{Accident,National,\"St Paul’S Bay\",Traffic}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4110</td>\n",
       "      <td>https://timesofmalta.com/article/skip-involved...</td>\n",
       "      <td>Times of Malta</td>\n",
       "      <td>https://timesofmalta.com</td>\n",
       "      <td>Skip involved in horror St Paul’s Bay bypass c...</td>\n",
       "      <td>Motorcyclist hurt in crash on Wednesday evenin...</td>\n",
       "      <td>Emma Borg</td>\n",
       "      <td>2024-12-12</td>\n",
       "      <td>A private contractor who placed a skip on St P...</td>\n",
       "      <td>https://cdn-attachments.timesofmalta.com/fc23e...</td>\n",
       "      <td>A 54-year-old man was seriously injured when h...</td>\n",
       "      <td>2025-07-03 15:13:54.812813+00</td>\n",
       "      <td>{Accident,National,\"St Paul’S Bay\"}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4066</td>\n",
       "      <td>https://timesofmalta.com/article/two-people-in...</td>\n",
       "      <td>Times of Malta</td>\n",
       "      <td>https://timesofmalta.com</td>\n",
       "      <td>Two people, including teenage girl, critically...</td>\n",
       "      <td>Incidents in Mellieħa and Gudja on Friday even...</td>\n",
       "      <td>Times of Malta</td>\n",
       "      <td>2024-12-14</td>\n",
       "      <td>A 29-year-old man and 17-year-old girl were cr...</td>\n",
       "      <td>https://cdn-attachments.timesofmalta.com/f1761...</td>\n",
       "      <td>The Ford Fiesta involved in the Gudja collisio...</td>\n",
       "      <td>2025-07-03 15:13:43.83839+00</td>\n",
       "      <td>{Accident,Gudja,Mellieħa,National,Traffic}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id                                                url  \\\n",
       "0        4208  https://timesofmalta.com/article/driver-stuck-...   \n",
       "1        4167  https://timesofmalta.com/article/pn-slams-gove...   \n",
       "2        4093  https://timesofmalta.com/article/motorcyclist-...   \n",
       "3        4110  https://timesofmalta.com/article/skip-involved...   \n",
       "4        4066  https://timesofmalta.com/article/two-people-in...   \n",
       "\n",
       "      source_name                source_url  \\\n",
       "0  Times of Malta  https://timesofmalta.com   \n",
       "1  Times of Malta  https://timesofmalta.com   \n",
       "2  Times of Malta  https://timesofmalta.com   \n",
       "3  Times of Malta  https://timesofmalta.com   \n",
       "4  Times of Malta  https://timesofmalta.com   \n",
       "\n",
       "                                               title  \\\n",
       "0  Driver stuck in traffic says speeding LESA car...   \n",
       "1  PN slams government for diverting EU bus funds...   \n",
       "2  Motorcyclist seriously hurt in St Paul's Bay b...   \n",
       "3  Skip involved in horror St Paul’s Bay bypass c...   \n",
       "4  Two people, including teenage girl, critically...   \n",
       "\n",
       "                                            subtitle     author_name  \\\n",
       "0  ‘I was shocked at that moment but more so frus...       Emma Borg   \n",
       "1  'By encouraging the use of private cars, the g...  Times of Malta   \n",
       "2  Residents complained several times about inade...  Times of Malta   \n",
       "3  Motorcyclist hurt in crash on Wednesday evenin...       Emma Borg   \n",
       "4  Incidents in Mellieħa and Gudja on Friday even...  Times of Malta   \n",
       "\n",
       "  publish_date                                            content  \\\n",
       "0   2024-12-07  A motorist claims his car mirror was shattered...   \n",
       "1   2024-12-09  The PN on Monday slammed the government for di...   \n",
       "2   2024-12-11  A motorcyclist was rushed to hospital in a cri...   \n",
       "3   2024-12-12  A private contractor who placed a skip on St P...   \n",
       "4   2024-12-14  A 29-year-old man and 17-year-old girl were cr...   \n",
       "\n",
       "                                       top_image_url  \\\n",
       "0  https://cdn-attachments.timesofmalta.com/706da...   \n",
       "1  https://cdn-attachments.timesofmalta.com/d9afe...   \n",
       "2  https://cdn-attachments.timesofmalta.com/633f6...   \n",
       "3  https://cdn-attachments.timesofmalta.com/fc23e...   \n",
       "4  https://cdn-attachments.timesofmalta.com/f1761...   \n",
       "\n",
       "                                   top_image_caption  \\\n",
       "0  The broken car mirror. Photo: Frank Xerri De Caro   \n",
       "1  PN spokespeople Ryan Callus, Mark Anthony Samm...   \n",
       "2                          Photo: Malta Police Force   \n",
       "3  A 54-year-old man was seriously injured when h...   \n",
       "4  The Ford Fiesta involved in the Gudja collisio...   \n",
       "\n",
       "                      created_at  \\\n",
       "0  2025-07-03 15:14:21.554132+00   \n",
       "1  2025-07-03 15:14:10.643172+00   \n",
       "2  2025-07-03 15:13:50.605708+00   \n",
       "3  2025-07-03 15:13:54.812813+00   \n",
       "4   2025-07-03 15:13:43.83839+00   \n",
       "\n",
       "                                                tags categories  \n",
       "0                           {Accident,Lesa,National}         {}  \n",
       "1  {\"Climate Change\",Environment,\"European Union\"...         {}  \n",
       "2        {Accident,National,\"St Paul’S Bay\",Traffic}         {}  \n",
       "3                {Accident,National,\"St Paul’S Bay\"}         {}  \n",
       "4         {Accident,Gudja,Mellieħa,National,Traffic}         {}  "
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('../../../data/local_news_articles.csv')\n",
    "\n",
    "# Display basic information\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nColumn names:\")\n",
    "print(df.columns.tolist())\n",
    "print(f\"\\nFirst few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80927bff",
   "metadata": {},
   "source": [
    "## Road Accident Classification\n",
    "\n",
    "Now let's create a comprehensive classification system that identifies road accidents based on multiple criteria:\n",
    "- Keywords in title and content\n",
    "- Tags containing 'Accident' or 'Traffic'\n",
    "- Specific road accident indicators (vehicles, injuries, crashes, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "2b918fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accidents identified: 235 (73.2%)\n"
     ]
    }
   ],
   "source": [
    "def classify_road_accident(row):\n",
    "    \"\"\"Classify if article is about a road accident.\"\"\"\n",
    "    text = (str(row['title']) + ' ' + str(row['content'])).lower()\n",
    "    tags = str(row['tags']).lower()\n",
    "    \n",
    "    # Exclude policy articles (government, budget, legislation, etc.)\n",
    "    policy_keywords = ['government', 'minister', 'policy', 'budget', 'funds', 'legislation', 'parliament', 'proposal', 'grant', 'incentive', 'subsidy']\n",
    "    if sum(1 for k in policy_keywords if k in text) >= 3:\n",
    "        return 0\n",
    "    \n",
    "    # Exclude non-accident traffic incidents\n",
    "    non_accident_keywords = ['speeding', 'speed gun', 'caught doing', 'clocked at', 'pothole', 'flat tyre', 'flat tire', 'road damage', 'traffic violation', 'employer']\n",
    "    if any(k in text for k in non_accident_keywords):\n",
    "        return 0\n",
    "    \n",
    "    person_vehicle_terms = ['motorcyclist', 'cyclist', 'pedestrian']\n",
    "    accident_keywords = ['crash', 'collision', 'injured', 'grievously injured', 'seriously injured', 'hit by', 'overturned', 'lost control', 'hit-and-run', 'run over']\n",
    "    vehicles = ['car', 'bus', 'truck', 'van', 'motorcycle', 'bike', 'bicycle', 'scooter', 'vehicle']\n",
    "    \n",
    "    has_person_vehicle = any(k in text for k in person_vehicle_terms)\n",
    "    has_accident_keyword = any(k in text for k in accident_keywords)\n",
    "    has_vehicle = any(v in text for v in vehicles)\n",
    "    \n",
    "    if 'accident' in tags and (has_vehicle or has_accident_keyword or has_person_vehicle):\n",
    "        return 1\n",
    "    if has_accident_keyword and (has_vehicle or has_person_vehicle):\n",
    "        return 1\n",
    "    if has_person_vehicle and (has_accident_keyword or 'accident' in tags):\n",
    "        return 1\n",
    "    \n",
    "    return 0\n",
    "\n",
    "df['is_road_accident'] = df.apply(classify_road_accident, axis=1)\n",
    "accidents_df = df[df['is_road_accident'] == 1].copy()\n",
    "\n",
    "print(f\"Accidents identified: {len(accidents_df)} ({len(accidents_df)/len(df)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072c9d11",
   "metadata": {},
   "source": [
    "## Extract Accident Date and Time\n",
    "\n",
    "Let's extract the date and time when the accident occurred from the article content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "db4b746b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High: 144 | Medium: 66 | Low: 25\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def parse_time_to_datetime(date_obj, time_str):\n",
    "    if not time_str or pd.isna(date_obj):\n",
    "        return None\n",
    "    try:\n",
    "        time_str = time_str.lower().strip().replace('.', ':')\n",
    "        time_obj = datetime.strptime(time_str, '%I:%M%p' if ':' in time_str else '%I%p').time()\n",
    "        date_only = date_obj.date() if isinstance(date_obj, pd.Timestamp) else (date_obj.date() if hasattr(date_obj, 'date') else date_obj)\n",
    "        return datetime.combine(date_only, time_obj)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def extract_accident_datetime(row):\n",
    "    text = str(row['content']).lower()\n",
    "    title = str(row['title']).lower()\n",
    "    try:\n",
    "        # Try multiple date formats\n",
    "        pub_date = pd.to_datetime(row['publish_date'])\n",
    "    except:\n",
    "        pub_date = None\n",
    "    \n",
    "    # Enhanced time patterns with more variations\n",
    "    time_patterns = [\n",
    "        r'at (?:around |about )?(\\d{1,2}(?:\\.\\d{2})?(?:am|pm))',\n",
    "        r'at (?:around |about )?(\\d{1,2}:\\d{2})\\s*([ap]\\.?m\\.?)',\n",
    "        r'(?:reported|occurred|happened|took place) at (?:around |about )?(\\d{1,2}:\\d{2})\\s*([ap]\\.?m\\.?)',\n",
    "        r'(?:reported|occurred|happened|took place) at (?:around |about )?(\\d{1,2}(?:\\.\\d{2})?(?:am|pm))',\n",
    "        r'at (?:around |about )?(\\d{1,2}:\\d{2})',  # Fallback without am/pm\n",
    "    ]\n",
    "    \n",
    "    extracted_time = None\n",
    "    for pattern in time_patterns:\n",
    "        match = re.search(pattern, text)\n",
    "        if match:\n",
    "            if len(match.groups()) == 2:\n",
    "                # Pattern with separate time and am/pm groups\n",
    "                time_part = match.group(1)\n",
    "                ampm_part = match.group(2).replace('.', '').replace(' ', '')\n",
    "                extracted_time = time_part + ampm_part\n",
    "            else:\n",
    "                extracted_time = match.group(1)\n",
    "            break\n",
    "    \n",
    "    # Enhanced day patterns - check both content and title\n",
    "    day_patterns = {\n",
    "        r'on monday': ('Monday', 0), \n",
    "        r'on tuesday': ('Tuesday', 1), \n",
    "        r'on wednesday': ('Wednesday', 2),\n",
    "        r'on thursday': ('Thursday', 3), \n",
    "        r'on friday': ('Friday', 4), \n",
    "        r'on saturday': ('Saturday', 5),\n",
    "        r'on sunday': ('Sunday', 6), \n",
    "        r'this (?:morning|afternoon|evening|night)': ('today', None),\n",
    "        r'(?:yesterday|last night)': ('yesterday', None),\n",
    "        r'last (?:monday|tuesday|wednesday|thursday|friday|saturday|sunday)': ('last_week', -7),\n",
    "    }\n",
    "    \n",
    "    extracted_day = None\n",
    "    accident_date = None\n",
    "    \n",
    "    # Check both title and content for day references\n",
    "    combined_text = title + ' ' + text\n",
    "    \n",
    "    for pattern, (day_value, weekday) in day_patterns.items():\n",
    "        if re.search(pattern, combined_text):\n",
    "            extracted_day = day_value\n",
    "            if pub_date is not None:\n",
    "                if day_value == 'today':\n",
    "                    accident_date = pub_date\n",
    "                elif day_value == 'yesterday':\n",
    "                    accident_date = pub_date - timedelta(days=1)\n",
    "                elif day_value == 'last_week':\n",
    "                    # For \"last Monday\", etc - go back to that day in the previous week\n",
    "                    target_day = pattern.split()[-1].rstrip(r')')\n",
    "                    day_map = {'monday': 0, 'tuesday': 1, 'wednesday': 2, 'thursday': 3, \n",
    "                              'friday': 4, 'saturday': 5, 'sunday': 6}\n",
    "                    if target_day in day_map:\n",
    "                        target_weekday = day_map[target_day]\n",
    "                        days_back = (pub_date.weekday() - target_weekday) % 7\n",
    "                        if days_back == 0:\n",
    "                            days_back = 7  # If same day, go back full week\n",
    "                        accident_date = pub_date - timedelta(days=days_back)\n",
    "                elif weekday is not None:\n",
    "                    # Calculate days back, ensuring we go into the past\n",
    "                    days_back = (pub_date.weekday() - weekday) % 7\n",
    "                    if days_back == 0:\n",
    "                        # If same weekday as publish date, assume it's today (0 days back)\n",
    "                        days_back = 0\n",
    "                    accident_date = pub_date - timedelta(days=days_back)\n",
    "            break\n",
    "    \n",
    "    # If no specific day found, assume accident date = publish date\n",
    "    if accident_date is None and pub_date is not None:\n",
    "        accident_date = pub_date\n",
    "    \n",
    "    # Combine date and time\n",
    "    if extracted_time:\n",
    "        accident_datetime = parse_time_to_datetime(accident_date, extracted_time)\n",
    "    else:\n",
    "        accident_datetime = pd.Timestamp(accident_date) if accident_date is not None else None\n",
    "    \n",
    "    # CRITICAL: Ensure accident_datetime is never after publish_date\n",
    "    # Compare dates only (not times) to avoid false positives on same-day accidents\n",
    "    if accident_datetime is not None and pub_date is not None:\n",
    "        accident_date_only = accident_datetime.date() if hasattr(accident_datetime, 'date') else accident_datetime\n",
    "        pub_date_only = pub_date.date() if hasattr(pub_date, 'date') else pub_date\n",
    "        \n",
    "        if accident_date_only > pub_date_only:\n",
    "            # If date is in the future, go back one week to the same weekday\n",
    "            accident_datetime = accident_datetime - timedelta(days=7)\n",
    "            accident_date = accident_datetime.date() if hasattr(accident_datetime, 'date') else accident_datetime\n",
    "    \n",
    "    return extracted_time, extracted_day, accident_date, accident_datetime\n",
    "\n",
    "accidents_df['accident_time'], accidents_df['accident_day'], accidents_df['accident_date'], accidents_df['accident_datetime'] = zip(*accidents_df.apply(extract_accident_datetime, axis=1))\n",
    "\n",
    "accidents_df['time_confidence'] = accidents_df.apply(\n",
    "    lambda row: 'High' if pd.notna(row['accident_time']) else ('Medium' if pd.notna(row['accident_day']) else 'Low'), axis=1\n",
    ")\n",
    "\n",
    "accidents_df['accident_hour'] = accidents_df['accident_datetime'].apply(lambda dt: dt.hour if pd.notna(dt) else None)\n",
    "\n",
    "accidents_df['accident_is_weekend'] = accidents_df['accident_datetime'].apply(\n",
    "    lambda dt: 1 if (pd.notna(dt) and dt.weekday() >= 5) else (0 if pd.notna(dt) else None)\n",
    ")\n",
    "\n",
    "accidents_df['publication_delay_hours'] = accidents_df.apply(\n",
    "    lambda row: max(0, (pd.to_datetime(row['publish_date']) - row['accident_datetime']).total_seconds() / 3600) if pd.notna(row['accident_datetime']) else None, axis=1\n",
    ")\n",
    "\n",
    "def categorize_time_of_day(dt):\n",
    "    if pd.isna(dt):\n",
    "        return None\n",
    "    hour = dt.hour\n",
    "    if 0 <= hour < 6: return 'Night (00:00-06:00)'\n",
    "    elif 6 <= hour < 12: return 'Morning (06:00-12:00)'\n",
    "    elif 12 <= hour < 18: return 'Afternoon (12:00-18:00)'\n",
    "    else: return 'Evening (18:00-00:00)'\n",
    "\n",
    "accidents_df['time_of_day_category'] = accidents_df['accident_datetime'].apply(categorize_time_of_day)\n",
    "\n",
    "# Add holiday/event/school indicators\n",
    "def get_holiday_event_status(dt):\n",
    "    \"\"\"\n",
    "    Determine if date is a holiday, event, or school holiday period.\n",
    "    \n",
    "    Returns: (is_holiday, is_event, is_school_holiday)\n",
    "    \"\"\"\n",
    "    if pd.isna(dt):\n",
    "        return 'no', 'no', 'no'\n",
    "    \n",
    "    date = dt.date() if hasattr(dt, 'date') else dt\n",
    "    year = date.year\n",
    "    month = date.month\n",
    "    day = date.day\n",
    "    \n",
    "    # Maltese public holidays (fixed dates)\n",
    "    # These are official public holidays that may affect traffic patterns due to\n",
    "    # increased leisure travel, celebrations, and reduced commercial activity\n",
    "    holidays = [\n",
    "        (1, 1),   # New Year's Day\n",
    "        (2, 10),  # St Paul's Shipwreck (Feast of St Paul's Shipwreck)\n",
    "        (3, 19),  # St Joseph's Day\n",
    "        (3, 31),  # Freedom Day (Jum il-Ħelsien)\n",
    "        (5, 1),   # Workers' Day (May Day)\n",
    "        (6, 7),   # Sette Giugno (Commemoration of 1919 riots)\n",
    "        (6, 29),  # St Peter & St Paul (L-Imnarja - major feast)\n",
    "        (8, 15),  # Assumption of Mary (Santa Marija - mid-summer holiday)\n",
    "        (9, 8),   # Victory Day (Our Lady of Victories)\n",
    "        (9, 21),  # Independence Day\n",
    "        (12, 8),  # Immaculate Conception\n",
    "        (12, 13), # Republic Day\n",
    "        (12, 25), # Christmas Day\n",
    "        (12, 26), # Boxing Day\n",
    "    ]\n",
    "    \n",
    "    # Variable holidays for 2024-2025 (change yearly based on lunar calendar)\n",
    "    # Good Friday and Easter Sunday dates vary each year\n",
    "    variable_holidays = {\n",
    "        2024: [(3, 29), (3, 30)],  # Good Friday, Easter Sunday 2024\n",
    "        2025: [(4, 18), (4, 19)],  # Good Friday, Easter Sunday 2025\n",
    "    }\n",
    "    \n",
    "    # School holidays periods (approximate)\n",
    "    # School holidays may affect traffic patterns due to families traveling,\n",
    "    # reduced rush-hour congestion, and increased daytime leisure traffic\n",
    "    # Returns 'yes' if accident occurred during school holidays, 'no' otherwise\n",
    "    school_holidays = [\n",
    "        ('summer', 6, 20, 9, 15),    # Summer break: June 20 - Sept 15 (longest holiday)\n",
    "        ('christmas', 12, 20, 1, 7), # Christmas break: Dec 20 - Jan 7 (crosses year boundary)\n",
    "        ('easter', 4, 10, 4, 20),    # Easter break: April 10-20 (approx, varies with Easter date)\n",
    "    ]\n",
    "    \n",
    "    # Notable events that affect traffic patterns (festa season, carnival, etc.)\n",
    "    # These events involve road closures, processions, increased pedestrian traffic,\n",
    "    # and visitors traveling to/from villages. Returns 'yes' during event periods\n",
    "    events = {\n",
    "        2024: [\n",
    "            (2, 10, 2, 13),  # Carnival 2024 (weekend of celebrations, street parties)\n",
    "            (6, 1, 9, 30),   # Festa season: June-Sept (village feasts throughout Malta)\n",
    "        ],\n",
    "        2025: [\n",
    "            (3, 1, 3, 4),    # Carnival 2025 (weekend of celebrations, street parties)\n",
    "            (6, 1, 9, 30),   # Festa season: June-Sept (village feasts throughout Malta)\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    is_holiday = 'no'\n",
    "    is_event = 'no'\n",
    "    is_school = 'no'\n",
    "    \n",
    "    # Check if it's a public holiday\n",
    "    # Priority: 'eve of' overrides 'yes' if accident is day before a holiday\n",
    "    if (month, day) in holidays:\n",
    "        is_holiday = 'yes'\n",
    "    elif year in variable_holidays and (month, day) in variable_holidays[year]:\n",
    "        is_holiday = 'yes'\n",
    "    \n",
    "    # Check if it's eve of a holiday (day before)\n",
    "    # Eve of holidays often have increased social activity and traffic\n",
    "    next_day = date + timedelta(days=1)\n",
    "    if (next_day.month, next_day.day) in holidays:\n",
    "        is_holiday = 'eve of'\n",
    "    elif year in variable_holidays and (next_day.month, next_day.day) in variable_holidays[year]:\n",
    "        is_holiday = 'eve of'\n",
    "    \n",
    "    # Check if during event period\n",
    "    if year in events:\n",
    "        for event_start_m, event_start_d, event_end_m, event_end_d in events[year]:\n",
    "            event_start = date.replace(month=event_start_m, day=event_start_d)\n",
    "            event_end = date.replace(month=event_end_m, day=event_end_d)\n",
    "            if event_start <= date <= event_end:\n",
    "                is_event = 'yes'\n",
    "                break\n",
    "    \n",
    "    # Check if during school holidays\n",
    "    for holiday_name, start_m, start_d, end_m, end_d in school_holidays:\n",
    "        try:\n",
    "            if start_m <= end_m:  # Same year period\n",
    "                start_date = date.replace(month=start_m, day=start_d)\n",
    "                end_date = date.replace(month=end_m, day=end_d)\n",
    "                if start_date <= date <= end_date:\n",
    "                    is_school = 'yes'\n",
    "                    break\n",
    "            else:  # Crosses year boundary (e.g., Christmas)\n",
    "                start_date = date.replace(month=start_m, day=start_d)\n",
    "                end_date = date.replace(year=date.year+1 if date.month < 6 else date.year, month=end_m, day=end_d)\n",
    "                if date >= start_date or date <= end_date:\n",
    "                    is_school = 'yes'\n",
    "                    break\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    return is_holiday, is_event, is_school\n",
    "\n",
    "accidents_df[['is_holiday', 'is_event', 'is_school_holiday']] = accidents_df['accident_datetime'].apply(\n",
    "    lambda dt: pd.Series(get_holiday_event_status(dt))\n",
    ")\n",
    "\n",
    "print(f\"High: {(accidents_df['time_confidence'] == 'High').sum()} | Medium: {(accidents_df['time_confidence'] == 'Medium').sum()} | Low: {(accidents_df['time_confidence'] == 'Low').sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "037d193c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved 235 accidents to ../../../data/processed/road_accidents_with_datetime.csv\n"
     ]
    }
   ],
   "source": [
    "for col in ['accident_datetime', 'accident_time', 'accident_day', 'accident_date', 'time_confidence', \n",
    "            'accident_hour', 'accident_is_weekend', 'publication_delay_hours', 'time_of_day_category', \n",
    "            'is_holiday', 'is_event', 'is_school_holiday']:\n",
    "    df[col] = None\n",
    "    df.loc[accidents_df.index, col] = accidents_df[col]\n",
    "\n",
    "columns_to_save = [col for col in accidents_df.columns if col not in ['accident_day', 'accident_hour']]\n",
    "accidents_output_path = '../../../data/processed/road_accidents_with_datetime.csv'\n",
    "accidents_df[columns_to_save].to_csv(accidents_output_path, index=False)\n",
    "\n",
    "print(f\"✓ Saved {len(accidents_df)} accidents to {accidents_output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b15a55",
   "metadata": {},
   "source": [
    "## Duplicate Article Detection and Flagging\n",
    "\n",
    "This section identifies potential duplicate articles in the combined news dataset by comparing key fields (`regxdt_accident_datetime`, `llm_street`, `llm_city`, and `llm__vehicle_type`) after normalizing them for case and whitespace. For each unique combination of these fields, only the second and subsequent unique `article_id` entries are flagged as potential duplicates. This ensures that only distinct articles (not multiple rows from the same article) are considered duplicates, and provides a list of previously seen `article_id`s for each flagged row to assist with manual review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547592d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Potential duplicates found: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\iscu02\\AppData\\Local\\Temp\\ipykernel_8628\\2143076461.py:42: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_combined.groupby(norm_cols, group_keys=False).apply(flag_second_and_later)\n",
      "C:\\Users\\iscu02\\AppData\\Local\\Temp\\ipykernel_8628\\2143076461.py:54: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_combined.groupby(norm_cols, group_keys=False).apply(get_previous_ids)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>previous_duplicate_article_ids</th>\n",
       "      <th>regxdt_accident_datetime</th>\n",
       "      <th>llm_street</th>\n",
       "      <th>llm_city</th>\n",
       "      <th>llm__vehicle_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3938</td>\n",
       "      <td>[3910]</td>\n",
       "      <td>2024-12-23 10:30:00</td>\n",
       "      <td>Regional Road</td>\n",
       "      <td>none</td>\n",
       "      <td>bus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3938</td>\n",
       "      <td>[3910]</td>\n",
       "      <td>2024-12-23 10:30:00</td>\n",
       "      <td>Regional Road</td>\n",
       "      <td>none</td>\n",
       "      <td>van</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>3635</td>\n",
       "      <td>[3615]</td>\n",
       "      <td>2025-01-13 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>3563</td>\n",
       "      <td>[3443]</td>\n",
       "      <td>2025-01-17 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>2028</td>\n",
       "      <td>[2022]</td>\n",
       "      <td>2025-04-03 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>2040</td>\n",
       "      <td>[2022, 2028]</td>\n",
       "      <td>2025-04-03 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>1388</td>\n",
       "      <td>[1387]</td>\n",
       "      <td>2025-05-05 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>53</td>\n",
       "      <td>[42]</td>\n",
       "      <td>2025-07-01 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>467297</td>\n",
       "      <td>[467185]</td>\n",
       "      <td>2025-07-29 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>489728</td>\n",
       "      <td>[489720]</td>\n",
       "      <td>2025-08-06 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>490929</td>\n",
       "      <td>[490742]</td>\n",
       "      <td>2025-08-18 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>491047</td>\n",
       "      <td>[490742, 490929]</td>\n",
       "      <td>2025-08-18 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>491307</td>\n",
       "      <td>[491226]</td>\n",
       "      <td>2025-08-22 05:30:00</td>\n",
       "      <td>Sir Anthony Mamo Street</td>\n",
       "      <td>Birkirkara</td>\n",
       "      <td>Car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>491307</td>\n",
       "      <td>[491226]</td>\n",
       "      <td>2025-08-22 05:30:00</td>\n",
       "      <td>Sir Anthony Mamo Street</td>\n",
       "      <td>Birkirkara</td>\n",
       "      <td>Motorcycle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>491437</td>\n",
       "      <td>[491380]</td>\n",
       "      <td>2025-08-24 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>491640</td>\n",
       "      <td>[491380, 491437]</td>\n",
       "      <td>2025-08-24 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>491651</td>\n",
       "      <td>[491568]</td>\n",
       "      <td>2025-08-26 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>491694</td>\n",
       "      <td>[491568, 491651]</td>\n",
       "      <td>2025-08-26 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>491738</td>\n",
       "      <td>[491568, 491651, 491694]</td>\n",
       "      <td>2025-08-26 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>491890</td>\n",
       "      <td>[491787]</td>\n",
       "      <td>2025-08-27 12:30:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>493223</td>\n",
       "      <td>[493121]</td>\n",
       "      <td>2025-09-09 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>496154</td>\n",
       "      <td>[496060]</td>\n",
       "      <td>2025-10-07 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>496586</td>\n",
       "      <td>[496577]</td>\n",
       "      <td>2025-10-13 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     article_id previous_duplicate_article_ids regxdt_accident_datetime  \\\n",
       "28         3938                         [3910]      2024-12-23 10:30:00   \n",
       "29         3938                         [3910]      2024-12-23 10:30:00   \n",
       "53         3635                         [3615]      2025-01-13 00:00:00   \n",
       "63         3563                         [3443]      2025-01-17 00:00:00   \n",
       "140        2028                         [2022]      2025-04-03 00:00:00   \n",
       "142        2040                   [2022, 2028]      2025-04-03 00:00:00   \n",
       "169        1388                         [1387]      2025-05-05 00:00:00   \n",
       "228          53                           [42]      2025-07-01 00:00:00   \n",
       "281      467297                       [467185]      2025-07-29 00:00:00   \n",
       "292      489728                       [489720]      2025-08-06 00:00:00   \n",
       "330      490929                       [490742]      2025-08-18 00:00:00   \n",
       "333      491047               [490742, 490929]      2025-08-18 00:00:00   \n",
       "340      491307                       [491226]      2025-08-22 05:30:00   \n",
       "339      491307                       [491226]      2025-08-22 05:30:00   \n",
       "346      491437                       [491380]      2025-08-24 00:00:00   \n",
       "351      491640               [491380, 491437]      2025-08-24 00:00:00   \n",
       "352      491651                       [491568]      2025-08-26 00:00:00   \n",
       "354      491694               [491568, 491651]      2025-08-26 00:00:00   \n",
       "359      491738       [491568, 491651, 491694]      2025-08-26 00:00:00   \n",
       "361      491890                       [491787]      2025-08-27 12:30:00   \n",
       "380      493223                       [493121]      2025-09-09 00:00:00   \n",
       "437      496154                       [496060]      2025-10-07 00:00:00   \n",
       "449      496586                       [496577]      2025-10-13 00:00:00   \n",
       "\n",
       "                  llm_street    llm_city llm__vehicle_type  \n",
       "28             Regional Road        none               bus  \n",
       "29             Regional Road        none               van  \n",
       "53                       NaN         NaN               NaN  \n",
       "63                       NaN         NaN               NaN  \n",
       "140                      NaN         NaN               NaN  \n",
       "142                      NaN         NaN               NaN  \n",
       "169                      NaN         NaN               NaN  \n",
       "228                      NaN         NaN               NaN  \n",
       "281                      NaN         NaN               NaN  \n",
       "292                      NaN         NaN               NaN  \n",
       "330                      NaN         NaN               NaN  \n",
       "333                      NaN         NaN               NaN  \n",
       "340  Sir Anthony Mamo Street  Birkirkara               Car  \n",
       "339  Sir Anthony Mamo Street  Birkirkara        Motorcycle  \n",
       "346                      NaN         NaN               NaN  \n",
       "351                      NaN         NaN               NaN  \n",
       "352                      NaN         NaN               NaN  \n",
       "354                      NaN         NaN               NaN  \n",
       "359                      NaN         NaN               NaN  \n",
       "361                      NaN         NaN               NaN  \n",
       "380                      NaN         NaN               NaN  \n",
       "437                      NaN         NaN               NaN  \n",
       "449                      NaN         NaN               NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Flagged duplicates saved to potential_duplicate_articles.csv\n"
     ]
    }
   ],
   "source": [
    "# Check for potential duplicate articles in combined_news_articles.csv\n",
    "import pandas as pd\n",
    "\n",
    "combined_path = '../../../data/processed/combined_news_articles.csv'\n",
    "df_combined = pd.read_csv(combined_path)\n",
    "\n",
    "# Normalize columns for duplicate detection (case-insensitive, remove whitespace)\n",
    "dup_cols = ['regxdt_accident_datetime', 'llm_street', 'llm_city', 'llm__vehicle_type']\n",
    "for col in dup_cols:\n",
    "    if col in df_combined.columns:\n",
    "        df_combined[col + '_norm'] = (\n",
    "            df_combined[col]\n",
    "            .astype(str)\n",
    "            .str.lower()\n",
    "            .str.replace(r'\\s+', '', regex=True)\n",
    "            .str.strip()\n",
    "        )\n",
    "    else:\n",
    "        df_combined[col + '_norm'] = ''\n",
    "\n",
    "norm_cols = [col + '_norm' for col in dup_cols]\n",
    "\n",
    "# For each row, flag only the second and subsequent articles (by article_id) with the same normalized keys\n",
    "if 'article_id' in df_combined.columns:\n",
    "    # Sort by normalized keys and article_id to ensure consistent ordering\n",
    "    df_combined = df_combined.sort_values(norm_cols + ['article_id'])\n",
    "    # For each group of normalized keys, flag only the second and subsequent unique article_ids\n",
    "    def flag_second_and_later(group):\n",
    "        seen = set()\n",
    "        flags = []\n",
    "        for aid in group['article_id']:\n",
    "            if aid in seen:\n",
    "                flags.append(False)\n",
    "            elif len(seen) == 0:\n",
    "                flags.append(False)\n",
    "                seen.add(aid)\n",
    "            else:\n",
    "                flags.append(True)\n",
    "                seen.add(aid)\n",
    "        return pd.Series(flags, index=group.index)\n",
    "    df_combined['potential_duplicate_article_id'] = (\n",
    "        df_combined.groupby(norm_cols, group_keys=False).apply(flag_second_and_later)\n",
    "    )\n",
    "    # For reporting, also show which article_ids are already present for the flagged row\n",
    "    def get_previous_ids(group):\n",
    "        seen = []\n",
    "        prev_ids = []\n",
    "        for aid in group['article_id']:\n",
    "            prev_ids.append(list(seen) if seen else None)\n",
    "            if aid not in seen:\n",
    "                seen.append(aid)\n",
    "        return pd.Series(prev_ids, index=group.index)\n",
    "    df_combined['previous_duplicate_article_ids'] = (\n",
    "        df_combined.groupby(norm_cols, group_keys=False).apply(get_previous_ids)\n",
    "    )\n",
    "else:\n",
    "    df_combined['potential_duplicate_article_id'] = False\n",
    "    df_combined['previous_duplicate_article_ids'] = None\n",
    "\n",
    "# Show flagged duplicates for review\n",
    "duplicates = df_combined[df_combined['potential_duplicate_article_id']]\n",
    "print(f\"Potential duplicates found: {len(duplicates)}\")\n",
    "if not duplicates.empty:\n",
    "    display_cols = (\n",
    "        ['article_id', 'previous_duplicate_article_ids'] + dup_cols + ['title', 'source']\n",
    "        if 'title' in df_combined.columns and 'source' in df_combined.columns\n",
    "        else ['article_id', 'previous_duplicate_article_ids'] + dup_cols\n",
    "    )\n",
    "    display(duplicates[display_cols].sort_values(dup_cols))\n",
    "\n",
    "# Optionally, save flagged duplicates for manual review\n",
    "duplicates.to_csv('../../../data/processed/potential_duplicate_articles_flagged.csv', index=False)\n",
    "print('✓ Flagged duplicates saved to potential_duplicate_articles.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ics5110",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "461f05bf-8fb0-4ebb-acbc-dbc6be301434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\iscu02\\appdata\\local\\miniconda3\\envs\\ics5110\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy>=1.23.2 in c:\\users\\iscu02\\appdata\\local\\miniconda3\\envs\\ics5110\\lib\\site-packages (from pandas) (2.3.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\iscu02\\appdata\\local\\miniconda3\\envs\\ics5110\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\iscu02\\appdata\\local\\miniconda3\\envs\\ics5110\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\iscu02\\appdata\\local\\miniconda3\\envs\\ics5110\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\iscu02\\appdata\\local\\miniconda3\\envs\\ics5110\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01427bba-4f5c-45ea-8ae9-f2557214c4c0",
   "metadata": {},
   "source": [
    "# Data Exploration & Feature Engineering\n",
    "\n",
    "This notebook processes police press releases and news articles to extract accident datetime information and prepare the data for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1bfa618a-3e5d-4c5d-b05a-2ef2fce3bb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import requests\n",
    "from typing import Dict, List\n",
    "import warnings\n",
    "import re\n",
    "import os\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration\n",
    "DATA_PATH = \"C:\\\\Python\\\\ics5110-assignment\\\\data\\\\\"\n",
    "OUTPUT_PATH = \"C:\\\\Python\\\\ics5110-assignment\\\\data\\\\processed\\\\\"\n",
    "os.makedirs(OUTPUT_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d44ab8-c251-4014-8177-7c9332b6c129",
   "metadata": {},
   "source": [
    "# 1. Load and Explore Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "67006ec0-f817-4982-98ca-bc3bd2724522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Articles dataset shape: (321, 14)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 321 entries, 0 to 320\n",
      "Data columns (total 14 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   article_id         321 non-null    int64 \n",
      " 1   url                321 non-null    object\n",
      " 2   source_name        321 non-null    object\n",
      " 3   source_url         321 non-null    object\n",
      " 4   title              321 non-null    object\n",
      " 5   subtitle           313 non-null    object\n",
      " 6   author_name        321 non-null    object\n",
      " 7   publish_date       321 non-null    object\n",
      " 8   content            321 non-null    object\n",
      " 9   top_image_url      318 non-null    object\n",
      " 10  top_image_caption  312 non-null    object\n",
      " 11  created_at         321 non-null    object\n",
      " 12  tags               321 non-null    object\n",
      " 13  categories         321 non-null    object\n",
      "dtypes: int64(1), object(13)\n",
      "memory usage: 35.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# Load articles dataset\n",
    "articles_df = pd.read_csv(f\"{DATA_PATH}local_news_articles.csv\")\n",
    "print(f\"Articles dataset shape: {articles_df.shape}\")\n",
    "articles_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7dbf8b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Police releases dataset shape: (111, 5)\n",
      "Primary key range: 1 to 111\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 111 entries, 0 to 110\n",
      "Data columns (total 5 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   release_id      111 non-null    int64 \n",
      " 1   title           111 non-null    object\n",
      " 2   date_published  111 non-null    object\n",
      " 3   date_modified   111 non-null    object\n",
      " 4   content         111 non-null    object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 4.5+ KB\n",
      "\n",
      "================================================================================\n",
      "Sample police press release:\n",
      "Release ID: 1\n",
      "Published: 2025-10-09\n",
      "Content: Today, at around 0930hrs, the Police were informed of a traffic accident on Triq il-Belt Valletta, Å»urrieq.The Police immediately went to the scene and from a preliminary investigation it resulted tha...\n"
     ]
    }
   ],
   "source": [
    "# Load police releases dataset with primary key\n",
    "police_releases_df = pd.read_csv(f\"{DATA_PATH}police_press_releases.csv\")\n",
    "police_releases_df.insert(0, 'release_id', range(1, len(police_releases_df) + 1))\n",
    "\n",
    "print(f\"Police releases dataset shape: {police_releases_df.shape}\")\n",
    "print(f\"Primary key range: {police_releases_df['release_id'].min()} to {police_releases_df['release_id'].max()}\")\n",
    "police_releases_df.info()\n",
    "\n",
    "# Display sample\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Sample police press release:\")\n",
    "print(f\"Release ID: {police_releases_df['release_id'].iloc[0]}\")\n",
    "print(f\"Published: {police_releases_df['date_published'].iloc[0]}\")\n",
    "print(f\"Content: {police_releases_df['content'].iloc[0][:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff882f5",
   "metadata": {},
   "source": [
    "# 2. Accident DateTime Extraction Function\n",
    "\n",
    "Extract accident date and time from police press release content with high accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f4a17949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Extraction function loaded\n"
     ]
    }
   ],
   "source": [
    "def extract_accident_datetime_improved(content: str, published_date: str) -> dict:\n",
    "    \"\"\"\n",
    "    Extract accident date and time from police press release content.\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with accident_datetime, accident_date, accident_time, time_confidence\n",
    "    \"\"\"\n",
    "    result = {\n",
    "        'accident_datetime': None,\n",
    "        'accident_date': None,\n",
    "        'accident_time': None,\n",
    "        'time_confidence': 'low'\n",
    "    }\n",
    "    \n",
    "    if pd.isna(content) or pd.isna(published_date):\n",
    "        return result\n",
    "    \n",
    "    content_lower = content.lower()\n",
    "    published_dt = pd.to_datetime(published_date)\n",
    "    extracted_time = None\n",
    "    \n",
    "    # HIGH confidence: Exact time with \"hrs\"\n",
    "    hrs_patterns = [\n",
    "        (r'at around (\\d{4})\\s*hrs', 1), (r'at (\\d{4})\\s*hrs', 1),\n",
    "        (r'around (\\d{4})\\s*hrs', 1), (r'\\((\\d{4})\\s*hrs\\)', 1),\n",
    "        (r'\\w+\\s*\\((\\d{4})\\s*hrs\\)', 1),\n",
    "        (r'at around (\\d{1,2}):(\\d{2})\\s*hrs', 2), (r'at (\\d{1,2}):(\\d{2})\\s*hrs', 2),\n",
    "        (r'around (\\d{1,2}):(\\d{2})\\s*hrs', 2),\n",
    "        (r'at around (\\d{1,2})\\.(\\d{2})\\s*hrs', 2), (r'at (\\d{1,2})\\.(\\d{2})\\s*hrs', 2),\n",
    "    ]\n",
    "    \n",
    "    for pattern, num_groups in hrs_patterns:\n",
    "        match = re.search(pattern, content_lower)\n",
    "        if match:\n",
    "            if num_groups == 1:\n",
    "                time_str = match.group(1)\n",
    "                if len(time_str) == 4:\n",
    "                    hour, minute = int(time_str[:2]), int(time_str[2:])\n",
    "                    if 0 <= hour <= 23 and 0 <= minute <= 59:\n",
    "                        extracted_time = f\"{hour:02d}:{minute:02d}\"\n",
    "                        result['time_confidence'] = 'high'\n",
    "                        break\n",
    "            else:\n",
    "                hour, minute = int(match.group(1)), int(match.group(2))\n",
    "                if 0 <= hour <= 23 and 0 <= minute <= 59:\n",
    "                    extracted_time = f\"{hour:02d}:{minute:02d}\"\n",
    "                    result['time_confidence'] = 'high'\n",
    "                    break\n",
    "    \n",
    "    # HIGH confidence: Standard time formats without \"hrs\"\n",
    "    if not extracted_time:\n",
    "        time_patterns = [\n",
    "            (r'at around (\\d{1,2}):(\\d{2})', 2), (r'at (\\d{1,2}):(\\d{2})', 2),\n",
    "            (r'around (\\d{1,2}):(\\d{2})', 2),\n",
    "            (r'at around (\\d{1,2})\\.(\\d{2})', 2), (r'at (\\d{1,2})\\.(\\d{2})', 2),\n",
    "        ]\n",
    "        for pattern, _ in time_patterns:\n",
    "            match = re.search(pattern, content_lower)\n",
    "            if match:\n",
    "                hour, minute = int(match.group(1)), int(match.group(2))\n",
    "                if 0 <= hour <= 23 and 0 <= minute <= 59:\n",
    "                    extracted_time = f\"{hour:02d}:{minute:02d}\"\n",
    "                    result['time_confidence'] = 'high'\n",
    "                    break\n",
    "    \n",
    "    # MEDIUM-HIGH confidence: Specific time markers\n",
    "    if not extracted_time:\n",
    "        time_markers = [\n",
    "            (r'\\bmidnight\\b', '00:00', 'high'), (r'\\bnoon\\b|\\bmidday\\b', '12:00', 'high'),\n",
    "            (r'\\bdawn\\b|\\bsunrise\\b', '06:00', 'medium'), (r'\\bdusk\\b|\\bsunset\\b', '19:00', 'medium'),\n",
    "        ]\n",
    "        for pattern, time, conf in time_markers:\n",
    "            if re.search(pattern, content_lower):\n",
    "                extracted_time, result['time_confidence'] = time, conf\n",
    "                break\n",
    "    \n",
    "    # MEDIUM confidence: Time ranges (calculate midpoint)\n",
    "    if not extracted_time:\n",
    "        match = re.search(r'between (\\d{1,2})[:\\.]?(\\d{2})?\\s*(?:and|&|-)\\s*(\\d{1,2})[:\\.]?(\\d{2})?', content_lower)\n",
    "        if match:\n",
    "            hour1 = int(match.group(1))\n",
    "            min1 = int(match.group(2)) if match.group(2) else 0\n",
    "            hour2 = int(match.group(3))\n",
    "            min2 = int(match.group(4)) if match.group(4) else 0\n",
    "            if 0 <= hour1 <= 23 and 0 <= hour2 <= 23:\n",
    "                mid_minutes = ((hour1 * 60 + min1) + (hour2 * 60 + min2)) // 2\n",
    "                extracted_time = f\"{mid_minutes // 60:02d}:{mid_minutes % 60:02d}\"\n",
    "                result['time_confidence'] = 'medium'\n",
    "    \n",
    "    # MEDIUM confidence: General time periods\n",
    "    if not extracted_time:\n",
    "        time_periods = [\n",
    "            (r'\\bearly hours\\b', '03:00'), (r'\\blate hours\\b|\\blate at night\\b', '23:00'),\n",
    "            (r'\\bearly morning\\b', '06:00'), (r'\\bmorning\\b', '09:00'),\n",
    "            (r'\\bafternoon\\b', '15:00'), (r'\\bevening\\b', '19:00'), (r'\\bnight\\b', '22:00'),\n",
    "        ]\n",
    "        for pattern, time in time_periods:\n",
    "            if re.search(pattern, content_lower):\n",
    "                extracted_time, result['time_confidence'] = time, 'medium'\n",
    "                break\n",
    "    \n",
    "    # Date extraction\n",
    "    accident_date = None\n",
    "    explicit_patterns = [\n",
    "        (r'on (\\d{1,2}(?:st|nd|rd|th)?\\s+(?:january|february|march|april|may|june|july|august|september|october|november|december))', '%d %B'),\n",
    "        (r'on ((?:january|february|march|april|may|june|july|august|september|october|november|december)\\s+\\d{1,2}(?:st|nd|rd|th)?)', '%B %d'),\n",
    "    ]\n",
    "    \n",
    "    for pattern, date_format in explicit_patterns:\n",
    "        match = re.search(pattern, content_lower)\n",
    "        if match:\n",
    "            try:\n",
    "                date_str = re.sub(r'(st|nd|rd|th)', '', match.group(1))\n",
    "                accident_date = pd.to_datetime(date_str, format=date_format).replace(year=published_dt.year)\n",
    "                if accident_date > published_dt + timedelta(days=30):\n",
    "                    accident_date = accident_date.replace(year=published_dt.year - 1)\n",
    "                break\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    if accident_date is None:\n",
    "        if re.search(r'^\\s*today[,\\s]|^today at', content_lower):\n",
    "            accident_date = published_dt\n",
    "        elif re.search(r'^\\s*yesterday[,\\s]|^yesterday at', content_lower):\n",
    "            accident_date = published_dt - timedelta(days=1)\n",
    "        elif re.search(r'\\bthis morning\\b', content_lower):\n",
    "            accident_date = published_dt\n",
    "        elif re.search(r'\\blast night\\b', content_lower):\n",
    "            accident_date = published_dt - timedelta(days=1)\n",
    "        elif re.search(r'\\blast evening\\b', content_lower):\n",
    "            accident_date = published_dt - timedelta(days=1)\n",
    "        elif match := re.search(r'\\blast (monday|tuesday|wednesday|thursday|friday|saturday|sunday)', content_lower):\n",
    "            days = ['monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday']\n",
    "            days_back = (published_dt.weekday() - days.index(match.group(1))) % 7 or 7\n",
    "            accident_date = published_dt - timedelta(days=days_back)\n",
    "        else:\n",
    "            accident_date = published_dt\n",
    "    \n",
    "    # Combine date and time\n",
    "    if accident_date is not None:\n",
    "        result['accident_date'] = accident_date.date()\n",
    "        if extracted_time:\n",
    "            try:\n",
    "                hour, minute = map(int, extracted_time.split(':'))\n",
    "                result['accident_datetime'] = accident_date.replace(hour=hour, minute=minute, second=0)\n",
    "                result['accident_time'] = extracted_time\n",
    "            except:\n",
    "                result['accident_datetime'] = accident_date\n",
    "        else:\n",
    "            result['accident_datetime'] = accident_date\n",
    "    \n",
    "    return result\n",
    "\n",
    "print(\"âœ“ Extraction function loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9533bc2c",
   "metadata": {},
   "source": [
    "# 3. Extract Accident DateTime for All Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "292f45f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting accident datetime...\n",
      "\n",
      "âœ“ Extraction complete!\n",
      "Total: 111 | High: 106 (95.5%) | Medium: 1 (0.9%) | Low: 4 (3.6%)\n",
      "\n",
      "âœ“ Extraction complete!\n",
      "Total: 111 | High: 106 (95.5%) | Medium: 1 (0.9%) | Low: 4 (3.6%)\n"
     ]
    }
   ],
   "source": [
    "print(\"Extracting accident datetime...\")\n",
    "\n",
    "# Apply extraction\n",
    "extraction_results = police_releases_df.apply(\n",
    "    lambda row: extract_accident_datetime_improved(row['content'], row['date_published']), axis=1\n",
    ")\n",
    "\n",
    "# Add columns\n",
    "extraction_df = pd.DataFrame(extraction_results.tolist())\n",
    "for col in ['accident_datetime', 'accident_date', 'accident_time', 'time_confidence']:\n",
    "    police_releases_df[col] = extraction_df[col]\n",
    "\n",
    "# Add derived features\n",
    "police_releases_df['accident_is_weekend'] = pd.to_datetime(police_releases_df['accident_datetime']).dt.dayofweek.isin([5, 6]).astype(int)\n",
    "police_releases_df['publication_delay_hours'] = ((\n",
    "    pd.to_datetime(police_releases_df['date_published']) - \n",
    "    pd.to_datetime(police_releases_df['accident_datetime'])\n",
    ").dt.total_seconds() / 3600).apply(lambda x: max(0, x) if pd.notna(x) else x)\n",
    "\n",
    "def categorize_time_of_day(hour):\n",
    "    if pd.isna(hour): return None\n",
    "    if 0 <= hour < 6: return 'Night (00:00-06:00)'\n",
    "    if 6 <= hour < 12: return 'Morning (06:00-12:00)'\n",
    "    if 12 <= hour < 18: return 'Afternoon (12:00-18:00)'\n",
    "    return 'Evening (18:00-00:00)'\n",
    "\n",
    "police_releases_df['time_of_day_category'] = pd.to_datetime(police_releases_df['accident_datetime']).dt.hour.apply(categorize_time_of_day)\n",
    "\n",
    "# Add holiday/event/school indicators\n",
    "def get_holiday_event_status(dt):\n",
    "    \"\"\"\n",
    "    Determine if date is a holiday, event, or school holiday period.\n",
    "    \n",
    "    Returns: (is_holiday, is_event, is_school_holiday)\n",
    "    \"\"\"\n",
    "    if pd.isna(dt):\n",
    "        return 'no', 'no', 'no'\n",
    "    \n",
    "    date = dt.date() if hasattr(dt, 'date') else dt\n",
    "    year = date.year\n",
    "    month = date.month\n",
    "    day = date.day\n",
    "    \n",
    "    # Maltese public holidays (fixed dates)\n",
    "    # These are official public holidays that may affect traffic patterns due to\n",
    "    # increased leisure travel, celebrations, and reduced commercial activity\n",
    "    holidays = [\n",
    "        (1, 1),   # New Year's Day\n",
    "        (2, 10),  # St Paul's Shipwreck (Feast of St Paul's Shipwreck)\n",
    "        (3, 19),  # St Joseph's Day\n",
    "        (3, 31),  # Freedom Day (Jum il-Ä¦elsien)\n",
    "        (5, 1),   # Workers' Day (May Day)\n",
    "        (6, 7),   # Sette Giugno (Commemoration of 1919 riots)\n",
    "        (6, 29),  # St Peter & St Paul (L-Imnarja - major feast)\n",
    "        (8, 15),  # Assumption of Mary (Santa Marija - mid-summer holiday)\n",
    "        (9, 8),   # Victory Day (Our Lady of Victories)\n",
    "        (9, 21),  # Independence Day\n",
    "        (12, 8),  # Immaculate Conception\n",
    "        (12, 13), # Republic Day\n",
    "        (12, 25), # Christmas Day\n",
    "        (12, 26), # Boxing Day\n",
    "    ]\n",
    "    \n",
    "    # Variable holidays for 2024-2025 (change yearly based on lunar calendar)\n",
    "    # Good Friday and Easter Sunday dates vary each year\n",
    "    variable_holidays = {\n",
    "        2024: [(3, 29), (3, 30)],  # Good Friday, Easter Sunday 2024\n",
    "        2025: [(4, 18), (4, 19)],  # Good Friday, Easter Sunday 2025\n",
    "    }\n",
    "    \n",
    "    # School holidays periods (approximate)\n",
    "    # School holidays may affect traffic patterns due to families traveling,\n",
    "    # reduced rush-hour congestion, and increased daytime leisure traffic\n",
    "    # Returns 'yes' if accident occurred during school holidays, 'no' otherwise\n",
    "    school_holidays = [\n",
    "        ('summer', 6, 20, 9, 15),    # Summer break: June 20 - Sept 15 (longest holiday)\n",
    "        ('christmas', 12, 20, 1, 7), # Christmas break: Dec 20 - Jan 7 (crosses year boundary)\n",
    "        ('easter', 4, 10, 4, 20),    # Easter break: April 10-20 (approx, varies with Easter date)\n",
    "    ]\n",
    "    \n",
    "    # Notable events that affect traffic patterns (festa season, carnival, etc.)\n",
    "    # These events involve road closures, processions, increased pedestrian traffic,\n",
    "    # and visitors traveling to/from villages. Returns 'yes' during event periods\n",
    "    events = {\n",
    "        2024: [\n",
    "            (2, 10, 2, 13),  # Carnival 2024 (weekend of celebrations, street parties)\n",
    "            (6, 1, 9, 30),   # Festa season: June-Sept (village feasts throughout Malta)\n",
    "        ],\n",
    "        2025: [\n",
    "            (3, 1, 3, 4),    # Carnival 2025 (weekend of celebrations, street parties)\n",
    "            (6, 1, 9, 30),   # Festa season: June-Sept (village feasts throughout Malta)\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    is_holiday = 'no'\n",
    "    is_event = 'no'\n",
    "    is_school = 'no'\n",
    "    \n",
    "    # Check if it's a public holiday\n",
    "    # Priority: 'eve of' overrides 'yes' if accident is day before a holiday\n",
    "    if (month, day) in holidays:\n",
    "        is_holiday = 'yes'\n",
    "    elif year in variable_holidays and (month, day) in variable_holidays[year]:\n",
    "        is_holiday = 'yes'\n",
    "    \n",
    "    # Check if it's eve of a holiday (day before)\n",
    "    # Eve of holidays often have increased social activity and traffic\n",
    "    next_day = date + timedelta(days=1)\n",
    "    if (next_day.month, next_day.day) in holidays:\n",
    "        is_holiday = 'eve of'\n",
    "    elif year in variable_holidays and (next_day.month, next_day.day) in variable_holidays[year]:\n",
    "        is_holiday = 'eve of'\n",
    "    \n",
    "    # Check if during event period\n",
    "    if year in events:\n",
    "        for event_start_m, event_start_d, event_end_m, event_end_d in events[year]:\n",
    "            event_start = date.replace(month=event_start_m, day=event_start_d)\n",
    "            event_end = date.replace(month=event_end_m, day=event_end_d)\n",
    "            if event_start <= date <= event_end:\n",
    "                is_event = 'yes'\n",
    "                break\n",
    "    \n",
    "    # Check if during school holidays\n",
    "    for holiday_name, start_m, start_d, end_m, end_d in school_holidays:\n",
    "        try:\n",
    "            if start_m <= end_m:  # Same year period\n",
    "                start_date = date.replace(month=start_m, day=start_d)\n",
    "                end_date = date.replace(month=end_m, day=end_d)\n",
    "                if start_date <= date <= end_date:\n",
    "                    is_school = 'yes'\n",
    "                    break\n",
    "            else:  # Crosses year boundary (e.g., Christmas)\n",
    "                start_date = date.replace(month=start_m, day=start_d)\n",
    "                end_date = date.replace(year=date.year+1 if date.month < 6 else date.year, month=end_m, day=end_d)\n",
    "                if date >= start_date or date <= end_date:\n",
    "                    is_school = 'yes'\n",
    "                    break\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    return is_holiday, is_event, is_school\n",
    "\n",
    "# Apply holiday/event/school detection\n",
    "police_releases_df[['is_holiday', 'is_event', 'is_school_holiday']] = police_releases_df['accident_datetime'].apply(\n",
    "    lambda dt: pd.Series(get_holiday_event_status(dt))\n",
    ")\n",
    "\n",
    "# Summary\n",
    "total = len(police_releases_df)\n",
    "high = (police_releases_df['time_confidence'] == 'high').sum()\n",
    "medium = (police_releases_df['time_confidence'] == 'medium').sum()\n",
    "low = (police_releases_df['time_confidence'] == 'low').sum()\n",
    "\n",
    "print(f\"\\nâœ“ Extraction complete!\")\n",
    "print(f\"Total: {total} | High: {high} ({high/total*100:.1f}%) | Medium: {medium} ({medium/total*100:.1f}%) | Low: {low} ({low/total*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84db588a",
   "metadata": {},
   "source": [
    "# 4. Manual Corrections for Low Confidence Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ee0b06fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low confidence records: 4\n",
      "\n",
      "ID: 16 | Published: 2025-04-17 | Current: None\n",
      "Content: An 80-year-old man, a resident of Santa LuÄ‹ija, was taken to Mater Dei Hospital for some injuries he sustained in a traffic accident in Luqa Road, Luq...\n",
      "--------------------------------------------------------------------------------\n",
      "ID: 25 | Published: 2024-12-27 | Current: None\n",
      "Content: Today, at about 0745hrs, the Police were informed of a traffic accident in Triq DiÄ‹embru Tlettax, Marsa.The Police went immediately on site and prelim...\n",
      "--------------------------------------------------------------------------------\n",
      "ID: 76 | Published: 2025-04-14 | Current: None\n",
      "Content: Yesterday, at about 1745hrs, the Police were informed of a traffic accident in BirÅ¼ebbuÄ¡a Road, BirÅ¼ebbuÄ¡a.Preliminary investigations found that a col...\n",
      "--------------------------------------------------------------------------------\n",
      "ID: 77 | Published: 2025-07-24 | Current: None\n",
      "Content: A 65-year-old man, a resident of MellieÄ§a, was taken to Mater Dei Hospital at about 1015 hrs after he was injured in an accident in Salina Road, Naxxa...\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Display low confidence records\n",
    "low_conf = police_releases_df[police_releases_df['time_confidence'] == 'low']\n",
    "print(f\"Low confidence records: {len(low_conf)}\\n\")\n",
    "\n",
    "if len(low_conf) > 0:\n",
    "    for idx, row in low_conf.head(10).iterrows():\n",
    "        print(f\"ID: {row['release_id']} | Published: {row['date_published']} | Current: {row['accident_time']}\")\n",
    "        print(f\"Content: {row['content'][:150]}...\")\n",
    "        print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d64beae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Release ID 25: 07:45\n",
      "âœ“ Release ID 76: 17:45\n",
      "âœ“ Release ID 77: 10:15\n",
      "\n",
      "âœ“ 3 manual corrections applied\n"
     ]
    }
   ],
   "source": [
    "# Manual corrections dictionary - add your corrections here\n",
    "manual_corrections = {\n",
    "    25: {'time': '07:45'},\n",
    "    76: {'time': '17:45'},\n",
    "    77: {'time': '10:15'}\n",
    "    # Add more: release_id: {'time': 'HH:MM', 'date': 'YYYY-MM-DD'}\n",
    "}\n",
    "\n",
    "def apply_manual_corrections(df, corrections):\n",
    "    \"\"\"Apply manual time/date corrections to the dataframe.\"\"\"\n",
    "    df = df.copy()\n",
    "    corrections_applied = 0\n",
    "    \n",
    "    for release_id, correction_data in corrections.items():\n",
    "        mask = df['release_id'] == release_id\n",
    "        if not mask.any():\n",
    "            print(f\"âš  Release ID {release_id} not found\")\n",
    "            continue\n",
    "        \n",
    "        idx = df[mask].index[0]\n",
    "        \n",
    "        # Determine date\n",
    "        if 'date' in correction_data:\n",
    "            new_date = pd.to_datetime(correction_data['date'])\n",
    "        else:\n",
    "            new_date = pd.to_datetime(df.loc[idx, 'accident_date'] if pd.notna(df.loc[idx, 'accident_date']) \n",
    "                                     else df.loc[idx, 'date_published'])\n",
    "        \n",
    "        # Apply time\n",
    "        if 'time' in correction_data:\n",
    "            try:\n",
    "                hour, minute = map(int, correction_data['time'].split(':'))\n",
    "                if 0 <= hour <= 23 and 0 <= minute <= 59:\n",
    "                    df.loc[idx, 'accident_time'] = f\"{hour:02d}:{minute:02d}\"\n",
    "                    df.loc[idx, 'accident_datetime'] = new_date.replace(hour=hour, minute=minute, second=0)\n",
    "                    df.loc[idx, 'accident_date'] = new_date.date()\n",
    "                    df.loc[idx, 'time_of_day_category'] = categorize_time_of_day(hour)\n",
    "                    df.loc[idx, 'time_confidence'] = 'manual'\n",
    "                    delay_hours = (pd.to_datetime(df.loc[idx, 'date_published']) - df.loc[idx, 'accident_datetime']).total_seconds() / 3600\n",
    "                    df.loc[idx, 'publication_delay_hours'] = max(0, delay_hours)\n",
    "                    corrections_applied += 1\n",
    "                    print(f\"âœ“ Release ID {release_id}: {correction_data['time']}\")\n",
    "                else:\n",
    "                    print(f\"âœ— Invalid time for {release_id}: {correction_data['time']}\")\n",
    "            except Exception as e:\n",
    "                print(f\"âœ— Error for {release_id}: {e}\")\n",
    "    \n",
    "    return df, corrections_applied\n",
    "\n",
    "if manual_corrections:\n",
    "    police_releases_df, num_applied = apply_manual_corrections(police_releases_df, manual_corrections)\n",
    "    print(f\"\\nâœ“ {num_applied} manual corrections applied\")\n",
    "else:\n",
    "    print(\"No manual corrections defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e725c6",
   "metadata": {},
   "source": [
    "# 5. Final Statistics & Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b9dac719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "FINAL DATASET STATISTICS\n",
      "================================================================================\n",
      "\n",
      "ðŸ“Š Confidence Distribution:\n",
      "   High:    106 ( 95.5%)\n",
      "   Medium:    1 (  0.9%)\n",
      "   Manual:    3 (  2.7%)\n",
      "   Low:       1 (  0.9%)\n",
      "\n",
      "   Coverage:  110 / 111 (99.1%)\n",
      "\n",
      "â° Time Distribution:\n",
      "time_of_day_category\n",
      "Afternoon (12:00-18:00)    29\n",
      "Evening (18:00-00:00)      27\n",
      "Morning (06:00-12:00)      46\n",
      "Night (00:00-06:00)         9\n",
      "Name: count, dtype: int64\n",
      "\n",
      "ðŸ“… Weekend vs Weekday:\n",
      "   Weekday: 74\n",
      "   Weekend: 37\n",
      "\n",
      "ðŸ“° Publication Timing:\n",
      "   Average delay: 1.55 hours\n",
      "   Median delay:  0.00 hours\n",
      "\n",
      "ðŸŽ‰ Holiday/Event/School Breakdown:\n",
      "   Holiday: {'no': np.int64(102), 'eve of': np.int64(7), 'yes': np.int64(2)}\n",
      "   Event: {'no': np.int64(69), 'yes': np.int64(42)}\n",
      "   School holiday: {'yes': np.int64(85), 'no': np.int64(26)}\n",
      "\n",
      "================================================================================\n",
      "   release_id   accident_datetime accident_time  accident_is_weekend  \\\n",
      "0           1 2025-10-09 09:30:00         09:30                    0   \n",
      "1           2 2025-06-19 18:30:00         18:30                    0   \n",
      "2           3 2025-05-12 08:00:00         08:00                    0   \n",
      "3           4 2025-07-29 18:00:00         18:00                    0   \n",
      "4           5 2025-04-06 20:45:00         20:45                    1   \n",
      "5           6 2025-04-15 08:50:00         08:50                    0   \n",
      "6           7 2025-07-23 10:30:00         10:30                    0   \n",
      "7           8 2025-08-03 08:15:00         08:15                    1   \n",
      "8           9 2025-06-14 15:45:00         15:45                    1   \n",
      "9          10 2024-12-28 09:15:00         09:15                    1   \n",
      "\n",
      "      time_of_day_category time_confidence is_holiday is_event  \\\n",
      "0    Morning (06:00-12:00)            high         no       no   \n",
      "1    Evening (18:00-00:00)            high         no      yes   \n",
      "2    Morning (06:00-12:00)            high         no       no   \n",
      "3    Evening (18:00-00:00)            high         no      yes   \n",
      "4    Evening (18:00-00:00)            high         no       no   \n",
      "5    Morning (06:00-12:00)            high         no       no   \n",
      "6    Morning (06:00-12:00)            high         no      yes   \n",
      "7    Morning (06:00-12:00)            high         no      yes   \n",
      "8  Afternoon (12:00-18:00)            high         no      yes   \n",
      "9    Morning (06:00-12:00)            high         no       no   \n",
      "\n",
      "  is_school_holiday  \n",
      "0                no  \n",
      "1                no  \n",
      "2               yes  \n",
      "3               yes  \n",
      "4               yes  \n",
      "5               yes  \n",
      "6               yes  \n",
      "7               yes  \n",
      "8                no  \n",
      "9               yes  \n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"FINAL DATASET STATISTICS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "total = len(police_releases_df)\n",
    "high = (police_releases_df['time_confidence'] == 'high').sum()\n",
    "medium = (police_releases_df['time_confidence'] == 'medium').sum()\n",
    "manual = (police_releases_df['time_confidence'] == 'manual').sum()\n",
    "low = (police_releases_df['time_confidence'] == 'low').sum()\n",
    "\n",
    "print(f\"\\nðŸ“Š Confidence Distribution:\")\n",
    "print(f\"   High:   {high:4d} ({high/total*100:5.1f}%)\")\n",
    "print(f\"   Medium: {medium:4d} ({medium/total*100:5.1f}%)\")\n",
    "print(f\"   Manual: {manual:4d} ({manual/total*100:5.1f}%)\")\n",
    "print(f\"   Low:    {low:4d} ({low/total*100:5.1f}%)\")\n",
    "print(f\"\\n   Coverage: {high+medium+manual:4d} / {total} ({(high+medium+manual)/total*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nâ° Time Distribution:\")\n",
    "print(police_releases_df['time_of_day_category'].value_counts().sort_index())\n",
    "\n",
    "print(f\"\\nðŸ“… Weekend vs Weekday:\")\n",
    "weekend_counts = police_releases_df['accident_is_weekend'].value_counts()\n",
    "print(f\"   Weekday: {weekend_counts.get(0, 0)}\")\n",
    "print(f\"   Weekend: {weekend_counts.get(1, 0)}\")\n",
    "\n",
    "print(f\"\\nðŸ“° Publication Timing:\")\n",
    "print(f\"   Average delay: {police_releases_df['publication_delay_hours'].mean():.2f} hours\")\n",
    "print(f\"   Median delay:  {police_releases_df['publication_delay_hours'].median():.2f} hours\")\n",
    "\n",
    "print(f\"\\nðŸŽ‰ Holiday/Event/School Breakdown:\")\n",
    "print(f\"   Holiday: {dict(police_releases_df['is_holiday'].value_counts())}\")\n",
    "print(f\"   Event: {dict(police_releases_df['is_event'].value_counts())}\")\n",
    "print(f\"   School holiday: {dict(police_releases_df['is_school_holiday'].value_counts())}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "\n",
    "# Sample output\n",
    "sample_cols = ['release_id', 'accident_datetime', 'accident_time', 'accident_is_weekend', \n",
    "               'time_of_day_category', 'time_confidence', 'is_holiday', 'is_event', 'is_school_holiday']\n",
    "               \n",
    "print(police_releases_df[sample_cols].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c024770",
   "metadata": {},
   "source": [
    "# 6. Save Final Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4a9925ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Datasets saved successfully!\n",
      "\n",
      "Files created:\n",
      "1. C:\\Python\\ics5110-assignment\\data\\processed\\police_releases_with_datetime.csv - Full dataset\n",
      "\n",
      "ðŸ“Š Dataset ready for analysis and modeling!\n"
     ]
    }
   ],
   "source": [
    "# Save full dataset\n",
    "police_releases_df.to_csv(f\"{OUTPUT_PATH}police_releases_with_datetime.csv\", index=False)\n",
    "\n",
    "# # Save summary dataset\n",
    "# summary_columns = [\n",
    "#     'release_id', 'date_published', 'accident_datetime', 'accident_date', \n",
    "#     'accident_time', 'accident_hour', 'time_of_day_category',\n",
    "#     'accident_day_of_week', 'accident_is_weekend', 'time_confidence',\n",
    "#     'publication_delay_hours', 'is_holiday', 'is_event', 'is_school_holiday'\n",
    "# ]\n",
    "# police_releases_df[summary_columns].to_csv(f\"{OUTPUT_PATH}police_releases_summary.csv\", index=False)\n",
    "\n",
    "# # Export low confidence for external review (CSV)\n",
    "# low_conf = police_releases_df[police_releases_df['time_confidence'] == 'low'][\n",
    "#     ['release_id', 'date_published', 'accident_time', 'accident_date', 'content']\n",
    "# ].copy()\n",
    "# low_conf['corrected_time'] = ''\n",
    "# low_conf['corrected_date'] = ''\n",
    "# low_conf.to_csv(f\"{OUTPUT_PATH}low_confidence_review.csv\", index=False)\n",
    "\n",
    "print(\"âœ“ Datasets saved successfully!\\n\")\n",
    "print(\"Files created:\")\n",
    "print(f\"1. {OUTPUT_PATH}police_releases_with_datetime.csv - Full dataset\")\n",
    "# print(f\"2. {OUTPUT_PATH}police_releases_summary.csv - Summary with key features\")\n",
    "# print(f\"3. {OUTPUT_PATH}low_confidence_review.csv - Low confidence records for manual review\")\n",
    "print(f\"\\nðŸ“Š Dataset ready for analysis and modeling!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ics5110",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

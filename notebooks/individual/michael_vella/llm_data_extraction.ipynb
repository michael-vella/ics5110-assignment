{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69ab15c5-4291-40ec-9d19-69c2a0dd8c70",
   "metadata": {},
   "source": [
    "# Reading & Resources\n",
    "\n",
    "- [GitHub Repository with a list of LLMs](https://github.com/cheahjs/free-llm-api-resources)\n",
    "- [Harnessing the power of LLMs for automated data extraction](https://www.seldon.io/harnessing-the-power-of-llms-for-automated-data-extraction/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51871345-81ed-4bf0-98b1-19ae22f2f350",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install python-dotenv\n",
    "!pip install pandas\n",
    "!pip install openai==2.8.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ae4e27-7bc3-4fb2-ab97-0d8713f8a8c0",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c933a13f-9f48-438b-bfdf-531824b7452c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "from IPython.display import display\n",
    "\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9c80b2-dd05-4949-9cab-6a0380dae000",
   "metadata": {},
   "source": [
    "# Data Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4f9aca-9c7d-47b7-855d-cc45aa0daf16",
   "metadata": {},
   "source": [
    "## Load env variables\n",
    "\n",
    "Environment variables include API Keys for LLMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2e5e95-79a0-4d43-801d-49715d9549d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f5b7a5-4cc0-4c98-a418-5f729b95b6e3",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3ef5b0-4f80-4fcc-8487-fb9c2df72a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "local_news_articles_csv = \"../../../data/local_news_articles.csv\"\n",
    "police_press_releases_csv = \"../../../data/police_press_releases.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a8a45e-f012-4ea2-99df-ffb93a498571",
   "metadata": {},
   "source": [
    "## Local News Articles\n",
    "\n",
    "Preprocessing of local news articles dataframe. We keep the `article_id` column just in case we need it later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affcff8e-814f-45e0-bf8d-eb649271afc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_df = pd.read_csv(local_news_articles_csv)\n",
    "\n",
    "print(\"Original News Articles DataFrame:\")\n",
    "display(articles_df) \n",
    "print(articles_df.info())\n",
    "\n",
    "articles_df = articles_df[\n",
    "    [\n",
    "        \"article_id\", # article id to trace back\n",
    "        \"title\",\n",
    "        \"subtitle\",\n",
    "        \"content\",\n",
    "        \"publish_date\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "articles_df[\"llm_input_text\"] = (\n",
    "    \"Title: \" + articles_df[\"title\"].fillna(\"\") + \"\\n\" +\n",
    "    \"Subtitle: \" + articles_df[\"subtitle\"].fillna(\"\") + \"\\n\" +\n",
    "    \"Content: \" + articles_df[\"content\"].fillna(\"\") + \"\\n\" +\n",
    "    \"Publish Date: \" + articles_df[\"publish_date\"].astype(str).fillna(\"none\")\n",
    ")\n",
    "\n",
    "print(\"News Articles DataFrame after selecting only interested columns\")\n",
    "display(articles_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e6e972-4100-461c-8f97-4bd792a4fb49",
   "metadata": {},
   "source": [
    "## Police Press Releases\n",
    "\n",
    "Preprocessing of police press releases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6248d4-cbaa-4146-8084-91ba23428990",
   "metadata": {},
   "outputs": [],
   "source": [
    "press_releases_df = pd.read_csv(police_press_releases_csv)\n",
    "press_releases_df.insert(0, 'release_id', range(1, len(press_releases_df) + 1)) # use similar pre-processing used by Isaac to generate surrogate key\n",
    "\n",
    "print(\"Original Press Releases DataFrame:\")\n",
    "display(press_releases_df) \n",
    "print(press_releases_df.info())\n",
    "\n",
    "press_releases_df = press_releases_df[\n",
    "    [\n",
    "        \"release_id\", # release_id\n",
    "        \"title\",\n",
    "        \"date_published\",\n",
    "        \"content\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "press_releases_df[\"llm_input_text\"] = (\n",
    "    \"Title: \" + press_releases_df[\"title\"].fillna(\"\") + \"\\n\" +\n",
    "    \"Content: \" + press_releases_df[\"content\"].fillna(\"\") + \"\\n\" +\n",
    "    \"Publish Date: \" + press_releases_df[\"date_published\"].astype(str).fillna(\"none\")\n",
    ")\n",
    "\n",
    "print(\"Police Press Releases DataFrame after selecting only interested columns\")\n",
    "display(press_releases_df) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68d9bf1-dd5b-4eaf-83ea-3c11fac0436a",
   "metadata": {},
   "source": [
    "## Using OpenAI Model\n",
    "\n",
    "Experimented with both o4-mini and 4o-mini. Decided on the 4o-mini due to returning structure JSON and slightly better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c3c092-0da1-4c8e-9c2e-5fa80f56aeca",
   "metadata": {},
   "source": [
    "### News Articles Prompt\n",
    "\n",
    "Prompt used to extract data from news articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d85ba7-1fa6-46a4-ac7c-f53ffd44a278",
   "metadata": {},
   "outputs": [],
   "source": [
    "NEWS_ARTICLES_PROMPT = \"\"\"\n",
    "You are a helpful data entry assistant whose responsibility is extracting traffic accident data from news articles.\n",
    "The following is such a news article. Please extract details of the accident and return them in a JSON dict with keys:\n",
    "\n",
    "- 'is_accident' (boolean) — true if the news article describes an actual traffic accident, false otherwise.\n",
    "- If 'is_accident' is true, include the following additional keys:\n",
    "    -'accident_datetime'\n",
    "    -'street'\n",
    "    -'city'\n",
    "    -'number_injured'\n",
    "    -'accident_severity'\n",
    "    -'drivers' (a list of objects, each with the following keys:)\n",
    "        -'vehicle_type'\n",
    "        -'vehicle_damage_severity'\n",
    "        -'driver_age'\n",
    "        -'driver_gender'\n",
    "        -'is_victim' (boolean)\n",
    "\n",
    "Please ensure that:\n",
    "-'incident_datetime' is in the format 'YYYY-MM-DD HH:MM' (24-hour format) if possible.\n",
    "-'number_injured' is an integer greater or equal to 0\n",
    "-'accident_severity' which relates to how severe the accident in terms of human injuries and and is one of: 'No Injuries', 'Minor', 'Serious' or 'Fatal'\n",
    "-'driver_gender' is either 'M' or 'F'.\n",
    "-'vehicle_damage_severity' is one of: 'No damage', 'Minor' or 'Major' where 'Minor' means small damages and 'Major' means total loss or big damages\n",
    "\n",
    "Please only return JSON—do not add any other text! If values are missing, set them to the string: \"none\".\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f378c2-02ae-4970-9203-f7366479afd1",
   "metadata": {},
   "source": [
    "### Police Press Releases Prompt\n",
    "\n",
    "Prompt used to extract data from police press releases using a LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86eb7319-106a-4a9d-99f6-f74fa250e0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "POLICE_PRESS_RELEASES_PROMPT = \"\"\"\n",
    "You are a helpful data entry assistant whose responsibility is extracting traffic accident data from police press releases.\n",
    "The following is such a press release. Please extract details of the accident and return them in a JSON dict with keys:\n",
    "\n",
    "- 'is_accident' (boolean) — true if the news article describes an actual traffic accident, false otherwise.\n",
    "- If 'is_accident' is true, include the following additional keys:\n",
    "    -'accident_datetime'\n",
    "    -'street'\n",
    "    -'city'\n",
    "    -'number_injured'\n",
    "    -'accident_severity'\n",
    "    -'drivers' (a list of objects, each with the following keys:)\n",
    "        -'vehicle_type'\n",
    "        -'vehicle_damage_severity'\n",
    "        -'driver_age'\n",
    "        -'driver_gender'\n",
    "        -'is_victim' (boolean)\n",
    "\n",
    "Please ensure that:\n",
    "-'incident_datetime' is in the format 'YYYY-MM-DD HH:MM' (24-hour format) if possible.\n",
    "-'number_injured' is an integer greater or equal to 0\n",
    "-'accident_severity' which relates to how severe the accident in terms of human injuries and and is one of: 'No Injuries', 'Minor', 'Serious' or 'Fatal'\n",
    "-'driver_gender' is either 'M' or 'F'.\n",
    "-'vehicle_damage_severity' is one of: 'No damage', 'Minor' or 'Major' where 'Minor' means small damages and 'Major' means total loss or big damages\n",
    "\n",
    "Please only return JSON—do not add any other text! If values are missing, set them to the string: \"none\".\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1089f7-c0c6-4e93-99bf-3d8fdc0a2f23",
   "metadata": {},
   "source": [
    "### Methods for LLM Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92152e4a-fcb4-48e5-8fbe-490b6d47673f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_llm_output(json_str: str) -> dict:\n",
    "    return json.loads(\n",
    "        json_str.replace(\"```json\", \"\").replace(\"```\", \"\")\n",
    "    )\n",
    "\n",
    "def extract_features_from_df(\n",
    "    pd_df: pd.DataFrame,\n",
    "    id_column: str,\n",
    "    prompt: str,\n",
    "    json_save_path: str\n",
    ") -> None:\n",
    "    client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "    results = []\n",
    "    \n",
    "    for index, row in pd_df.iterrows():\n",
    "        id_value = row[id_column]\n",
    "        input_text = row[\"llm_input_text\"]\n",
    "\n",
    "        retry_count = 0\n",
    "        success = False\n",
    "    \n",
    "        print(f\"Processing row with {id_column} '{id_value}'...\")   \n",
    "\n",
    "        while retry_count < 3 and not success:\n",
    "            try:\n",
    "                response = client.responses.create(\n",
    "                    model=\"o4-mini-2025-04-16\",\n",
    "                    instructions=prompt,\n",
    "                    input=input_text,\n",
    "                )\n",
    "                \n",
    "                llm_output = extract_llm_output(response.output_text)\n",
    "                llm_output[\"id_column\"] = id_value\n",
    "                llm_output[\"input_text\"] = input_text\n",
    "                results.append(llm_output)\n",
    "\n",
    "                print(f\"Successfully processed row with {id_column} '{id_value}'\")\n",
    "                success = True\n",
    "            except Exception as e:\n",
    "                retry_count += 1\n",
    "                print(f\"Error for row with {id_column} '{id_value}' (attempt {retry_count}/3): {e}\")\n",
    "\n",
    "                if retry_count < 3:\n",
    "                    time.sleep(2)  # backoff retry delay\n",
    "                else:\n",
    "                    print(f\"Failed to process row with {id_column} '{id_value}' after 3 attempts\")\n",
    "        \n",
    "    with open(json_save_path, 'w') as f:\n",
    "        json.dump(results, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52a1dc4-06d0-4a4d-8f6e-25f6cf9c025c",
   "metadata": {},
   "source": [
    "### Extraction and Analysis of News Articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fbeb6d-e907-427e-b947-8bfa5975cc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_articles_json = \"raw_articles.json\"\n",
    "\n",
    "if os.path.isfile(raw_articles_json):\n",
    "    print(\"LLM Feature Extraction from news articles was already done\")\n",
    "else:\n",
    "    extract_features_from_df(\n",
    "        pd_df=articles_df,\n",
    "        id_column=\"article_id\",\n",
    "        prompt=NEWS_ARTICLES_PROMPT,\n",
    "        json_save_path=raw_articles_json,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7e3858-d787-4728-a8fa-9e3cc22c7b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# processed by the LLM\n",
    "processed_articles_df = pd.read_json(raw_articles_json)\n",
    "processed_articles_df.to_csv(\"../../../data/processed/llm_local_news_articles.csv\")\n",
    "\n",
    "display(processed_articles_df)\n",
    "\n",
    "processed_articles_df[\"is_accident\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bd249c-468c-4e24-8c21-4fd39ec38657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rows that the LLM did not manage to process\n",
    "unprocessed_articles_df = articles_df[~articles_df[\"article_id\"].isin(processed_articles_df[\"id_column\"])] \n",
    "\n",
    "display(unprocessed_articles_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee05849f-4e4a-4ed5-b1c5-5e57ccc1bd91",
   "metadata": {},
   "source": [
    "### Extraction and Analysis of Police Press Releases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287151f7-f76f-47db-9a5e-ff99cb819963",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_press_releases_json = \"raw_press_releases.json\"\n",
    "\n",
    "if os.path.isfile(raw_press_releases_json):\n",
    "    print(\"LLM Feature Extraction from police press releases was already done\")\n",
    "else:\n",
    "    extract_features_from_df(\n",
    "        pd_df=press_releases_df,\n",
    "        id_column=\"release_id\",\n",
    "        prompt=POLICE_PRESS_RELEASES_PROMPT,\n",
    "        json_save_path=raw_press_releases_json,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ae6578-22f9-41e0-9378-027fb6fb7abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# processed by the LLM\n",
    "processed_press_releases_df = pd.read_json(raw_press_releases_json)\n",
    "processed_press_releases_df.to_csv(\"../../../data/processed/llm_press_releases.csv\")\n",
    "\n",
    "display(processed_press_releases_df)\n",
    "\n",
    "processed_press_releases_df[\"is_accident\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d9f747-3c93-4a1a-b05e-8f3a3bbb41b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rows that the LLM did not manage to process\n",
    "unprocessed_press_releases_df = press_releases_df[~press_releases_df[\"release_id\"].isin(processed_press_releases_df[\"id_column\"])] \n",
    "\n",
    "display(unprocessed_press_releases_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

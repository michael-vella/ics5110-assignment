{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3146fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import requests\n",
    "import logging\n",
    "import random\n",
    "\n",
    "INPUT_FILE = \"../../../data/processed/dim_street.csv\"\n",
    "OUTPUT_FILE = \"dim_street_enriched.csv\"\n",
    "LOG_FILE = \"nominatim_street_enrichment.log\"\n",
    "\n",
    "NOMINATIM_URL = \"https://nominatim.openstreetmap.org/search\"\n",
    "\n",
    "HEADERS = {\n",
    "    # MUST be descriptive + real contact\n",
    "    \"User-Agent\": \"street-verification/1.0 (contact: said.paul@gmail.com)\"\n",
    "}\n",
    "\n",
    "BASE_DELAY = 1.2        # seconds (policy-safe)\n",
    "MAX_RETRIES = 3\n",
    "\n",
    "# --------------------\n",
    "# Logging\n",
    "# --------------------\n",
    "logging.basicConfig(\n",
    "    filename=LOG_FILE,\n",
    "    filemode=\"w\",\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s | %(levelname)s | %(message)s\"\n",
    ")\n",
    "\n",
    "logging.info(\"Starting Nominatim street enrichment\")\n",
    "\n",
    "df = pd.read_csv(INPUT_FILE)\n",
    "\n",
    "for col in [\"chatgpt_lat\", \"chatgpt_lon\", \"chatgpt_street_type\"]:\n",
    "    if col not in df.columns:\n",
    "        df[col] = \"\"\n",
    "\n",
    "def polite_sleep():\n",
    "    time.sleep(BASE_DELAY + random.uniform(0.2, 0.6))\n",
    "\n",
    "def query_nominatim(street, town):\n",
    "    params = {\n",
    "        \"q\": f\"{street}, {town}, Malta\",\n",
    "        \"format\": \"json\",\n",
    "        \"addressdetails\": 1,\n",
    "        \"limit\": 3\n",
    "    }\n",
    "\n",
    "    for attempt in range(1, MAX_RETRIES + 1):\n",
    "        try:\n",
    "            r = requests.get(\n",
    "                NOMINATIM_URL,\n",
    "                params=params,\n",
    "                headers=HEADERS,\n",
    "                timeout=30\n",
    "            )\n",
    "\n",
    "            if r.status_code in (429, 503):\n",
    "                wait = BASE_DELAY * attempt * 2\n",
    "                logging.warning(\n",
    "                    f\"Rate-limited (HTTP {r.status_code}), \"\n",
    "                    f\"retry {attempt}/{MAX_RETRIES}, sleeping {wait:.1f}s\"\n",
    "                )\n",
    "                time.sleep(wait)\n",
    "                continue\n",
    "\n",
    "            r.raise_for_status()\n",
    "            return r.json()\n",
    "\n",
    "        except requests.RequestException as e:\n",
    "            logging.error(\n",
    "                f\"Request error on attempt {attempt}/{MAX_RETRIES}: {e}\"\n",
    "            )\n",
    "            time.sleep(BASE_DELAY * attempt)\n",
    "\n",
    "    return []\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "\n",
    "    if not row.get(\"is_canonical\", False):\n",
    "        continue\n",
    "\n",
    "    street = str(row.get(\"street\", \"\")).strip()\n",
    "    town = str(row.get(\"town_name\", \"\")).strip()\n",
    "\n",
    "    if not street or not town:\n",
    "        logging.warning(f\"Row {idx}: missing street/town\")\n",
    "        continue\n",
    "\n",
    "    logging.info(f\"Row {idx}: querying '{street}, {town}'\")\n",
    "\n",
    "    results = query_nominatim(street, town)\n",
    "    logging.info(f\"Row {idx}: {len(results)} result(s) returned\")\n",
    "\n",
    "    accepted = False\n",
    "\n",
    "    if results:\n",
    "        # If we got at least one result, accept the first one\n",
    "        res = results[0]\n",
    "        res_type = res.get(\"type\")\n",
    "        \n",
    "        # ACCEPT\n",
    "        df.at[idx, \"chatgpt_lat\"] = res.get(\"lat\", \"\")\n",
    "        df.at[idx, \"chatgpt_lon\"] = res.get(\"lon\", \"\")\n",
    "        df.at[idx, \"chatgpt_street_type\"] = res_type\n",
    "\n",
    "        logging.info(\n",
    "            f\"Row {idx}: ACCEPTED \"\n",
    "            f\"lat={res.get('lat')} lon={res.get('lon')} type={res_type}\"\n",
    "        )\n",
    "        accepted = True\n",
    "\n",
    "    if not accepted:\n",
    "        logging.info(f\"Row {idx}: NOT_FOUND\")\n",
    "\n",
    "    polite_sleep()\n",
    "\n",
    "df.to_csv(OUTPUT_FILE, index=False)\n",
    "\n",
    "logging.info(\"Completed enrichment safely\")\n",
    "logging.info(f\"Output: {OUTPUT_FILE}\")\n",
    "logging.info(f\"Log: {LOG_FILE}\")\n",
    "\n",
    "print(\"Done safely.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85363a6",
   "metadata": {},
   "source": [
    "# Configuration: Nominatim contact\n",
    "\n",
    "Set an environment variable `NOMINATIM_CONTACT` to a valid email or URL per Nominatim usage policy so requests are accepted.\n",
    "\n",
    "Examples (Windows PowerShell):\n",
    "\n",
    "- `$env:NOMINATIM_CONTACT = \"name@domain.tld\"`\n",
    "- `$env:NOMINATIM_CONTACT = \"https://yourdomain.tld/contact\"`\n",
    "\n",
    "This notebook will use that value to build the `User-Agent`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2303e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import requests\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3.util.retry import Retry\n",
    "import pandas as pd\n",
    "\n",
    "# -----------------------\n",
    "# CONFIG\n",
    "# -----------------------\n",
    "INPUT_CSV = \"../../../data/processed/dim_street.csv\"\n",
    "OUTPUT_CSV = \"../../../data/processed/dim_street_with_chatgpt_cols.csv\"\n",
    "NOMINATIM_URL = \"https://nominatim.openstreetmap.org/search\"\n",
    "ENABLE_REVERSE_FALLBACK = False  # set True to try reverse lookup when not class=highway\n",
    "HEADERS = {\n",
    "    \"User-Agent\": CONTACT_HEADER,\n",
    "    \"Accept-Language\": \"en\"\n",
    "}\n",
    "\n",
    "SLEEP_SECONDS = 1\n",
    "\n",
    "# -----------------------\n",
    "# LOAD DATA\n",
    "# -----------------------\n",
    "df = pd.read_csv(INPUT_CSV)\n",
    "\n",
    "for col in [\"chatgpt_lat\", \"chatgpt_lon\", \"chatgpt_street_type\", \"chatgpt_road_class\"]:\n",
    "    if col not in df.columns:\n",
    "        df[col] = None\n",
    "\n",
    "canonical_mask = df[\"is_canonical\"].astype(str).str.upper() == \"TRUE\"\n",
    "\n",
    "total_rows = int(canonical_mask.sum())\n",
    "if total_rows == 0:\n",
    "    print(\"No canonical rows to process.\")\n",
    "else:\n",
    "    print(f\"Starting geocoding for {total_rows} canonical rows...\")\n",
    "\n",
    "# -----------------------\n",
    "# Helpers\n",
    "# -----------------------\n",
    "ROAD_CLASS_NORMALIZATION = {\n",
    "    \"primary\": \"primary\",\n",
    "    \"primary_link\": \"primary_link\",\n",
    "    \"secondary\": \"secondary\",\n",
    "    \"secondary_link\": \"secondary_link\",\n",
    "    \"tertiary\": \"tertiary\",\n",
    "    \"tertiary_link\": \"tertiary_link\",\n",
    "    \"residential\": \"residential\",\n",
    "    \"unclassified\": \"unclassified\",\n",
    "    \"service\": \"service\",\n",
    "    \"living_street\": \"living_street\",\n",
    "    \"pedestrian\": \"pedestrian\",\n",
    "    \"track\": \"track\",\n",
    "    \"path\": \"path\",\n",
    "    \"cycleway\": \"cycleway\",\n",
    "    \"trunk\": \"trunk\",\n",
    "    \"trunk_link\": \"trunk_link\",\n",
    "    \"motorway\": \"motorway\",\n",
    "    \"motorway_link\": \"motorway_link\",\n",
    "}\n",
    "\n",
    "def extract_highway_type(result):\n",
    "    cls = result.get(\"class\")\n",
    "    typ = result.get(\"type\")\n",
    "    extratags = result.get(\"extratags\", {})\n",
    "    if cls == \"highway\" and typ:\n",
    "        return typ\n",
    "    return extratags.get(\"highway\")\n",
    "\n",
    "def normalize_road_class(hw: str | None) -> str:\n",
    "    if not hw:\n",
    "        return \"unknown\"\n",
    "    hw = str(hw).strip().lower()\n",
    "    return ROAD_CLASS_NORMALIZATION.get(hw, hw)\n",
    "\n",
    "# -----------------------\n",
    "# HTTP session with retries\n",
    "# -----------------------\n",
    "session = requests.Session()\n",
    "retry = Retry(\n",
    "    total=3,\n",
    "    backoff_factor=1,\n",
    "    status_forcelist=[403, 429, 500, 502, 503, 504],\n",
    "    allowed_methods=[\"GET\"],\n",
    ")\n",
    "adapter = HTTPAdapter(max_retries=retry)\n",
    "session.mount(\"https://\", adapter)\n",
    "session.mount(\"http://\", adapter)\n",
    "\n",
    "# -----------------------\n",
    "# Counters\n",
    "# -----------------------\n",
    "successes = 0\n",
    "no_matches = 0\n",
    "skips = 0\n",
    "errors = 0\n",
    "\n",
    "# -----------------------\n",
    "# GEOCODING LOOP\n",
    "# -----------------------\n",
    "for i, (idx, row) in enumerate(df[canonical_mask].iterrows(), start=1):\n",
    "    street = str(row[\"street\"]).strip()\n",
    "    town = str(row[\"town_name\"]).strip()\n",
    "\n",
    "    percent_complete = (i / total_rows) * 100 if total_rows else 0\n",
    "    print(f\"Progress: {i}/{total_rows} ({percent_complete:.1f}%)\")\n",
    "    print(f\"Query: street='{street}', town='{town}'\")\n",
    "\n",
    "    if not street or not town:\n",
    "        print(\"Result: skipped (missing street or town)\")\n",
    "        skips += 1\n",
    "        time.sleep(SLEEP_SECONDS + random.uniform(0.2, 0.7))\n",
    "        continue\n",
    "\n",
    "    params = {\n",
    "        \"q\": f\"{street}, {town}, Malta\",\n",
    "        \"format\": \"jsonv2\",\n",
    "        \"limit\": 1,\n",
    "        \"addressdetails\": 1,\n",
    "        \"extratags\": 1\n",
    "    }\n",
    "\n",
    "    response = None\n",
    "    try:\n",
    "        response = session.get(\n",
    "            NOMINATIM_URL,\n",
    "            params=params,\n",
    "            headers=HEADERS,\n",
    "            timeout=30\n",
    "        )\n",
    "        response.raise_for_status()\n",
    "        results = response.json()\n",
    "\n",
    "        if results:\n",
    "            result = results[0]\n",
    "\n",
    "            lat = float(result.get(\"lat\"))\n",
    "            lon = float(result.get(\"lon\"))\n",
    "            df.at[idx, \"chatgpt_lat\"] = lat\n",
    "            df.at[idx, \"chatgpt_lon\"] = lon\n",
    "\n",
    "            result_class = result.get(\"class\")\n",
    "            result_type = result.get(\"type\")\n",
    "            highway_type = extract_highway_type(result)\n",
    "            road_class = normalize_road_class(highway_type)\n",
    "            df.at[idx, \"chatgpt_street_type\"] = highway_type\n",
    "            df.at[idx, \"chatgpt_road_class\"] = road_class\n",
    "\n",
    "            display_name = result.get(\"display_name\", \"\")\n",
    "            print(\n",
    "                f\"Result: lat={lat}, lon={lon}, class='{result_class}', type='{result_type}', highway='{highway_type}', road_class='{road_class}', display_name='{display_name[:120]}'\"\n",
    "            )\n",
    "            print(\n",
    "                \"Output applied: lat={}, lon={}, road_class='{}'\".format(lat, lon, road_class)\n",
    "            )\n",
    "            successes += 1\n",
    "        else:\n",
    "            print(\"Result: none (no matches)\")\n",
    "            no_matches += 1\n",
    "\n",
    "    except Exception as e:\n",
    "        status = getattr(response, \"status_code\", None)\n",
    "        msg = f\"Result: error ({e})\"\n",
    "        if status is not None:\n",
    "            msg += f\", status={status}\"\n",
    "        print(msg)\n",
    "        if response is not None:\n",
    "            try:\n",
    "                txt = response.text or \"\"\n",
    "                if txt:\n",
    "                    print(f\"Response snippet: {txt[:200].replace('\\n',' ')}\")\n",
    "            except Exception:\n",
    "                pass\n",
    "        if status in (403, 429):\n",
    "            time.sleep(2 + random.uniform(0, 1))\n",
    "        errors += 1\n",
    "\n",
    "    time.sleep(SLEEP_SECONDS + random.uniform(0.2, 0.7))\n",
    "\n",
    "# -----------------------\n",
    "# WRITE OUTPUT + SUMMARY\n",
    "# -----------------------\n",
    "df.to_csv(OUTPUT_CSV, index=False)\n",
    "\n",
    "print(f\"Done. Output written to {OUTPUT_CSV}\")\n",
    "print(f\"Summary: successes={successes}, no_matches={no_matches}, skips={skips}, errors={errors}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
